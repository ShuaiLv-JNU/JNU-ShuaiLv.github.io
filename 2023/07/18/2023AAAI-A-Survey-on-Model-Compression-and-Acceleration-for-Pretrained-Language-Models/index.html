<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Hexo Theme Redefine">
    
    <meta name="author" content="Shuai Lv">
    <!-- preconnect -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    
    
        
            <link rel="preconnect" href="https://npm.elemecdn.com" crossorigin>
        
    
    <!--- Seo Part-->
    
    <link rel="canonical" href="http://blogls.top/2023/07/18/2023aaai-a-survey-on-model-compression-and-acceleration-for-pretrained-language-models/"/>
    <meta name="robots" content="index,follow">
    <meta name="googlebot" content="index,follow">
    <meta name="revisit-after" content="1 days">
    
        <meta name="description" content="1. Intro1.1 核心问题 在预训练语言模型的压缩和加速中，哪些方法是最有效的？这些方法的优缺点是什么？ 常用的方法包括权重共享、低秩分解、剪枝、量化、知识蒸馏、早期退出和跳过某些token等。其中，低秩分解是一种常用的方法，可以将神经网络中的权重矩阵分解成两个或多个较小的矩阵，从而减少模型参数数量，提高存储效率。另外，剪枝可以通过去除不重要的权重来减少模型大小，量化可以将浮点数权重转换为整">
<meta property="og:type" content="article">
<meta property="og:title" content="2023AAAI-A Survey on Model Compression and Acceleration for Pretrained Language Models">
<meta property="og:url" content="http://blogls.top/2023/07/18/2023AAAI-A-Survey-on-Model-Compression-and-Acceleration-for-Pretrained-Language-Models/index.html">
<meta property="og:site_name" content="乐愚良">
<meta property="og:description" content="1. Intro1.1 核心问题 在预训练语言模型的压缩和加速中，哪些方法是最有效的？这些方法的优缺点是什么？ 常用的方法包括权重共享、低秩分解、剪枝、量化、知识蒸馏、早期退出和跳过某些token等。其中，低秩分解是一种常用的方法，可以将神经网络中的权重矩阵分解成两个或多个较小的矩阵，从而减少模型参数数量，提高存储效率。另外，剪枝可以通过去除不重要的权重来减少模型大小，量化可以将浮点数权重转换为整">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://raw.githubusercontent.com/ShuaiLv-JNU/blogImage/main/img/202307182217268.png">
<meta property="og:image" content="https://raw.githubusercontent.com/ShuaiLv-JNU/blogImage/main/img/202307182238152.png">
<meta property="og:image" content="https://raw.githubusercontent.com/ShuaiLv-JNU/blogImage/main/img/202307182246532.png">
<meta property="og:image" content="https://raw.githubusercontent.com/ShuaiLv-JNU/blogImage/main/img/202307182248402.png">
<meta property="og:image" content="https://raw.githubusercontent.com/ShuaiLv-JNU/blogImage/main/img/202307182249972.png">
<meta property="article:published_time" content="2023-07-18T13:29:41.000Z">
<meta property="article:modified_time" content="2023-07-18T14:51:11.620Z">
<meta property="article:author" content="Shuai Lv">
<meta property="article:tag" content="LLM">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://raw.githubusercontent.com/ShuaiLv-JNU/blogImage/main/img/202307182217268.png">
    
    
        <!-- Google tag (gtag.js) -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-Q3ZMF4ZML1"></script>
        <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-Q3ZMF4ZML1');
        </script>
    
    <!--- Icon Part-->
    <link rel="icon" type="image/png" href="/images/favicon.svg" sizes="192x192">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.svg">
    <meta name="theme-color" content="#A31F34">
    <link rel="shortcut icon" href="/images/favicon.svg">
    <!--- Page Info-->
    
    <title>
        
            2023AAAI-A Survey on Model Compression and Acceleration for Pretrained Language Models -
        
        LeYuLiang
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="stylesheet" href="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/assets/fonts.css">
    <!--- Font Part-->
    
    
    
    

    <!--- Inject Part-->
    
    <script id="hexo-configurations">
    let Global = window.Global || {};
    Global.hexo_config = {"hostname":"blogls.top","root":"/","language":"en","path":"search.xml"};
    Global.theme_config = {"articles":{"style":{"font_size":"16px","line_height":1.5,"image_border_radius":"14px","image_alignment":"center","image_caption":false,"link_icon":true},"word_count":{"enable":true,"count":true,"min2read":true},"author_label":{"enable":true,"auto":true,"list":[]},"code_block":{"copy":true,"style":"mac","font":{"enable":false,"family":null,"url":null}},"toc":{"enable":true,"max_depth":3,"number":false,"expand":true,"init_open":true},"copyright":true,"lazyload":true,"recommendation":{"enable":true,"title":"推荐阅读","limit":3,"placeholder":"/images/wallhaven-wqery6-light.webp","skip_dirs":[]}},"colors":{"primary":"#A31F34","secondary":null},"global":{"fonts":{"chinese":{"enable":false,"family":null,"url":null},"english":{"enable":false,"family":null,"url":null}},"content_max_width":"1000px","sidebar_width":"210px","hover":{"shadow":true,"scale":false},"scroll_progress":{"bar":true,"percentage":true},"busuanzi_counter":{"enable":true,"site_pv":true,"site_uv":true,"post_pv":true},"pjax":true,"open_graph":true,"google_analytics":{"enable":true,"id":"G-Q3ZMF4ZML1"}},"home_banner":{"enable":true,"style":"fixed","image":{"light":"/images/wallhaven-wqery6-light.webp","dark":"/images/wallhaven-wqery6-dark.webp"},"title":"LeYuLiang's Blog","subtitle":{"text":["丈夫处世兮，立功名","立功名兮，慰平生","慰平生兮，吾将醉","吾将醉兮，发狂吟"],"hitokoto":{"enable":true,"api":"https://v1.hitokoto.cn"},"typing_speed":100,"backing_speed":80,"starting_delay":500,"backing_delay":1500,"loop":true,"smart_backspace":true},"text_color":{"light":"#fff","dark":"#d1d1b6"},"text_style":{"title_size":"2.8rem","subtitle_size":"1.5rem","line_height":1.2},"custom_font":{"enable":false,"family":null,"url":null},"social_links":{"enable":true,"links":{"github":"https://github.com/ShuaiLv-JNU","instagram":"https://www.instagram.com/liang_leyu/","zhihu":"https://www.zhihu.com/people/darker-7-73","twitter":"https://twitter.com/lushuai66337858","email":"lvshuai@stu2022.jnu.edu.cn"}}},"plugins":{"feed":{"enable":false},"aplayer":{"enable":true,"type":"fixed","audios":[{"name":"Something Just Like This","artist":"Coldplay","url":"https://evan.beee.top/music/Something%20Just%20Like%20This%20-%20The%20Chainsmokers%E3%80%81Coldplay.mp3","cover":"https://evan.beee.top/music/covers/Something_Just_Like_This.png"}]},"mermaid":{"enable":true,"version":"9.3.0"}},"version":"2.1.4","navbar":{"auto_hide":true,"color":{"left":"#f78736","right":"#367df7","transparency":35},"links":{"Home":{"path":"/","icon":"fa-regular fa-house"},"Archives":{"path":"/archives","icon":"fa-regular fa-archive"},"Resources":{"icon":"fa-regular fa-folder","submenus":{"Photo":"/masonry"}},"About":{"icon":"fa-regular fa-user","submenus":{"Me":"/about","Github":"https://github.com/ShuaiLv-JNU"}},"Links":{"path":"/links","icon":"fa-regular fa-link"}},"search":{"enable":false,"preload":true}},"page_templates":{"friends_column":2,"tags_style":"blur"},"home":{"sidebar":{"enable":true,"position":"left","first_item":"menu","announcement":"You only live once, so make sense.","links":{"Archives":{"path":"/archives","icon":"fa-regular fa-archive"},"Tags":{"path":"/tags","icon":"fa-regular fa-tags"},"Categories":{"path":"/categories","icon":"fa-regular fa-folder"}}},"article_date_format":"auto","categories":{"enable":true,"limit":3},"tags":{"enable":true,"limit":3}}};
    Global.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
    Global.data_config = {"masonry":true};
  </script>
    
    <!--- Fontawesome Part-->
    <link rel="stylesheet" href="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/fontawesome/fontawesome.min.css">
    <link rel="stylesheet" href="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/fontawesome/brands.min.css">
    <link rel="stylesheet" href="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/fontawesome/solid.min.css">
    <link rel="stylesheet" href="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/fontawesome/regular.min.css">
    
    
    
    
<meta name="generator" content="Hexo 5.4.2"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/rss2.xml" title="乐愚良" type="application/rss+xml">
</head>


<body>
<div class="progress-bar-container">
    
        <span class="scroll-progress-bar"></span>
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fa-solid fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="main-content-container">

        <div class="main-content-header">
            <header class="navbar-container">
    
    <div class="navbar-content">
        <div class="left">
            
                <a class="logo-image" href="/">
                    <img src="/images/logo.svg">
                </a>
            
            <a class="logo-title" href="/">
                
                LeYuLiang
                
            </a>
        </div>

        <div class="right">
            <!-- PC -->
            <div class="desktop">
                <ul class="navbar-list">
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/"  >
                                    
                                        
                                            <i class="fa-regular fa-house"></i>
                                        
                                        HOME
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/archives"  >
                                    
                                        
                                            <i class="fa-regular fa-archive"></i>
                                        
                                        ARCHIVES
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="has-dropdown" 
                                    href="#" onClick="return false;">
                                    
                                        
                                            <i class="fa-regular fa-folder"></i>
                                        
                                        RESOURCES&nbsp;<i class="fa-solid fa-chevron-down"></i>
                                    
                                </a>
                                <!-- Submenu -->
                                
                                    <ul class="sub-menu">
                                    
                                        <li>
                                        <a href="/masonry">PHOTO
                                        </a>
                                        </li>
                                    
                                    </ul>
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="has-dropdown" 
                                    href="#" onClick="return false;">
                                    
                                        
                                            <i class="fa-regular fa-user"></i>
                                        
                                        ABOUT&nbsp;<i class="fa-solid fa-chevron-down"></i>
                                    
                                </a>
                                <!-- Submenu -->
                                
                                    <ul class="sub-menu">
                                    
                                        <li>
                                        <a href="/about">ME
                                        </a>
                                        </li>
                                    
                                        <li>
                                        <a target="_blank" rel="noopener" href="https://github.com/ShuaiLv-JNU">GITHUB
                                        </a>
                                        </li>
                                    
                                    </ul>
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/links"  >
                                    
                                        
                                            <i class="fa-regular fa-link"></i>
                                        
                                        LINKS
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                    
                </ul>
            </div>
            <!-- Mobile -->
            <div class="mobile">
                
                <div class="icon-item navbar-bar">
                    <div class="navbar-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <!-- Mobile drawer -->
    <div class="navbar-drawer">
        <ul class="drawer-navbar-list">
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="" 
                        href="/"  >
                             
                                
                                    <i class="fa-regular fa-house"></i>
                                
                                HOME
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="" 
                        href="/archives"  >
                             
                                
                                    <i class="fa-regular fa-archive"></i>
                                
                                ARCHIVES
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="has-dropdown" 
                        href="#" onClick="return false;">
                            
                                
                                    <i class="fa-regular fa-folder"></i>
                                
                                RESOURCES&nbsp;<i class="fa-solid fa-chevron-down"></i>
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                              
                        
                            <li class="dropdown-item flex-center">
                                <a class="dropdown-item" href="/masonry">PHOTO</a>
                            </li>
                        
                    
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="has-dropdown" 
                        href="#" onClick="return false;">
                            
                                
                                    <i class="fa-regular fa-user"></i>
                                
                                ABOUT&nbsp;<i class="fa-solid fa-chevron-down"></i>
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                              
                        
                            <li class="dropdown-item flex-center">
                                <a class="dropdown-item" href="/about">ME</a>
                            </li>
                        
                            <li class="dropdown-item flex-center">
                                <a class="dropdown-item" target="_blank" rel="noopener" href="https://github.com/ShuaiLv-JNU">GITHUB</a>
                            </li>
                        
                    
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="" 
                        href="/links"  >
                             
                                
                                    <i class="fa-regular fa-link"></i>
                                
                                LINKS
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            

        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="main-content-body">

            

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="post-page-container">
        <div class="article-content-container">

            
            
                <div class="article-title">
                    <h1 class="article-title-regular">2023AAAI-A Survey on Model Compression and Acceleration for Pretrained Language Models</h1>
                </div>
            
                
            

            
                <div class="article-header">
                    <div class="avatar">
                        <img src="/images/avatar.jpg">
                    </div>
                    <div class="info">
                        <div class="author">
                            <span class="name">Shuai Lv</span>
                            
                                <span class="author-label">Lv3</span>
                            
                        </div>
                        <div class="meta-info">
                            <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fa-regular fa-pen-fancy"></i>&nbsp;
        <span class="desktop">2023-07-18 21:29:41</span>
        <span class="mobile">2023-07-18 21:29</span>
        <span class="hover-info">Created</span>
    </span>
    
        <span class="article-date article-meta-item">
            <i class="fa-regular fa-wrench"></i>&nbsp;
            <span class="desktop">2023-07-18 22:51:11</span>
            <span class="mobile">2023-07-18 22:51</span>
            <span class="hover-info">Updated</span>
        </span>
    

    
    
        <span class="article-tags article-meta-item">
            <i class="fa-regular fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/LLM/">LLM</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fa-regular fa-typewriter"></i>&nbsp;<span>9k Words</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fa-regular fa-clock"></i>&nbsp;<span>31 Mins</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                        </div>
                    </div>
                </div>
            

            <div class="article-content markdown-body">
                <h1 id="1-Intro"><a href="#1-Intro" class="headerlink" title="1. Intro"></a>1. Intro</h1><h2 id="1-1-核心问题"><a href="#1-1-核心问题" class="headerlink" title="1.1 核心问题"></a>1.1 核心问题</h2><ol>
<li><p>在预训练语言模型的压缩和加速中，哪些方法是最有效的？这些方法的优缺点是什么？</p>
<p>常用的方法包括权重共享、低秩分解、剪枝、量化、知识蒸馏、早期退出和跳过某些token等。其中，低秩分解是一种常用的方法，可以将神经网络中的权重矩阵分解成两个或多个较小的矩阵，从而减少模型参数数量，提高存储效率。另外，剪枝可以通过去除不重要的权重来减少模型大小，量化可以将浮点数权重转换为整数权重，从而减少存储空间和计算量。知识蒸馏可以通过让一个小模型学习一个大模型的知识来压缩模型。早期退出和跳过某些token等方法可以在保证一定精度的情况下加速模型推理速度。不同的方法各有优缺点，需要根据具体任务、数据、硬件等因素进行选择和组合。</p>
</li>
<li><p>如何评估模型压缩和加速的效果？当前的评估方法存在哪些不足之处？有没有更好的评估方法？</p>
<p>首先，缺乏一个普遍认可的评估设置，不同研究往往会得到不同的速度提升比例、参数数量和准确率等结果，难以直接进行比较，更不用说硬件差异。其次，通用的NLU基准测试如GLUE或SuperGLUE可能不是代表移动设备上更常见的任务，如意图检测、密集检索和垃圾邮件分类等。因此，需要更具代表性的任务来评估模型压缩和加速的效果。对于如何评估模型压缩和加速的效果，目前还没有更好的评估方法。</p>
</li>
<li><p>在模型压缩和加速中，知识蒸馏、剪枝和动态量化等方法有何异同？它们在不同场景下的适用性如何？</p>
<p>知识蒸馏、剪枝和动态量化是常用的模型压缩和加速方法。其中，知识蒸馏是将一个大模型的知识转移到一个小模型中，以达到加速和压缩的目的。剪枝是通过删除模型中的冗余参数来减小模型的大小，从而实现压缩和加速。动态量化是将模型中的参数从高精度浮点数转换为低精度整数，以减少模型的大小和计算量。这些方法在不同场景下的适用性不同。例如，知识蒸馏适用于需要在计算资源有限的设备上运行模型的场景，而剪枝适用于需要在存储资源有限的设备上运行模型的场景。动态量化适用于需要在低功耗设备上运行模型的场景。在实际应用中，这些方法也可以结合使用，以达到更好的效果。</p>
</li>
</ol>
<h2 id="1-2-abstract"><a href="#1-2-abstract" class="headerlink" title="1.2 abstract"></a>1.2 abstract</h2><p>高效的NLP研究旨在综合考虑NLP的整个生命周期的计算、时间和碳排放，包括数据准备、模型训练和推理。在本综述中，我们重点关注<strong>推理</strong>阶段，并回顾了预训练语言模型的模型压缩和加速的现状，包括基准、指标和方法论。</p>
<h2 id="1-3-introduction"><a href="#1-3-introduction" class="headerlink" title="1.3 introduction"></a>1.3 introduction</h2><p>高效推理指的是旨在使ML模型的推理更快(时间高效)、消耗更少的计算资源(计算高效)、更少的内存(内存高效)和更少的磁盘空间(存储高效)的技术。一种流行的技术是模型压缩和加速，将一个大而慢的模型压缩为一个轻量级的模型，可以在移动设备上有限的磁盘空间中存储，或加速以低延迟运行(或两者兼有)。此外，训练一个大型模型，然后将其压缩为一个小型模型，可以有效地进行训练，并有利于泛化。</p>
<p>这篇survey回顾了指标、基准和方法，将这些工作组织在一个新的分类法中。比较分析涵盖了广泛使用的技术，包括<strong>权重共享、低秩因子分解、剪枝、量化、知识蒸馏、提前退出和令牌跳过</strong>。</p>
<p>但没有以下内容：</p>
<ol>
<li>从头开始设计训练新架构的方法(例如，远程transformer，专家混合模型)；</li>
<li>更关注训练效率而不是推理效率的数据高效或参数高效的模型调优(例如，少样本学习、快速学习、部分模型调优)；</li>
<li>使用本文调查的技术但用于其他目的或特定于应用的工作(例如，自蒸馏、用于检索的表示蒸馏)。</li>
</ol>
<h1 id="2-detail"><a href="#2-detail" class="headerlink" title="2. detail"></a>2. detail</h1><h2 id="2-1-metric"><a href="#2-1-metric" class="headerlink" title="2.1 metric"></a>2.1 metric</h2><p>有各种各样的指标来描述不同维度的推理效率：**浮点操作(FLOPs)**直接度量执行一个实例所需的浮点操作的数量。FLOPs可以作为计算效率的度量，并且在某种程度上与硬件无关。然而，由于不同算法的并行度(DOP)不同，FLOPs不能准确反映实际运行时。</p>
<p>**推理时间(即延迟)**用于测量算法在其推理阶段的运行时间。在不同的基础设施上，推理时间可能会有所不同。在同一架构上进行测试时，与FLOPs相比，推理时间可以考虑并行性来更好地接近系统的实际性能。</p>
<p><strong>加速比</strong>是基线模型与加速模型的推理时间之比。与推理时间相比，加速比绘制了一个相对比较，可以在不同硬件上进行粗略比较。在一些工作中，加速比近似为基线模型中的Transformer层数与加速方法计算中使用的Transformer层数之比。</p>
<p>在NLP研究中，<strong>参数数量和模型大小</strong>经常被报告为直接反映模型存储成本的指标。由于移动设备上的存储空间有限，这对于NLP模型的移动部署非常重要。它也可以是训练和推理的内存占用和计算成本的指标。一个例外是具有<strong>重量共享</strong>的模型，例如，具有相同层数的ALBERT模型的FLOPs和内存使用略高于BERT模型。然而，由于ALBERT中的所有Transformer层共享相同的权重，因此n层ALBERT的模型尺寸仅为n层BERT的1/n。</p>
<p><strong>碳足迹衡量</strong>的是环境影响。La-coste et al.通过查询主流云计算提供商的碳排放数据库，为CO2提供了一个计算器。另外，实验影响跟踪器和CodeCarbon1是两个可以记录硬件能源使用并根据地理位置估计碳排放的插件。</p>
<p>Xu等人和Stanton等人分别提出了<strong>忠诚</strong>。两者都是在教师-学生蒸馏或压缩的设置中，在教师和学生的预测分布之间计算的相似性度量，可以反映知识从教师到学生转移的成功程度，提供可解释性和可靠性，并且可以作为提取大型教师模型和集合的更好泛化的指标。</p>
<p><strong>鲁棒性</strong> Su et al.发现，<u>较小的神经网络更容易受到对抗性攻击</u>。Xu等人建议除了准确性之外，还要报告对抗性稳健性。除了对抗性鲁棒性，Du发现，<u>压缩的预训练语言模型在分布外(OOD)数据上的鲁棒性明显较差。</u></p>
<h2 id="2-2-benchmark"><a href="#2-2-benchmark" class="headerlink" title="2.2 benchmark"></a>2.2 benchmark</h2><p>标准基准大多数研究都是在常见的NLP基准上进行评估的。例如，GLUE 和SuperGLUE 被用于自然语言处理(NLU)。SQuAD用于机器阅读理解(MRC)。</p>
<p><strong>Efficient qa</strong>是一个开放领域的问题回答基准，鼓励解决方案以最少的字节数有效地存储和访问知识。Efficient  qa有三个资源受限的轨道，包括两个6 GB和500 GB的轨道MB为系统大小的截断和一个轨道，以最小的大小对达到25%精度的系统进行排名。</p>
<p><strong>SustaiNLP</strong>  2020的共享任务使用SuperGLUE 来评估提交的性能。有三个轨迹针对不同的精度水平和硬件(2个GPU轨迹和1个CPU轨迹)。在每个曲目中，提交的作品按最低能耗进行排名，由实验影响跟踪器测量。</p>
<p><strong>ELUE</strong> 高效语言理解评估是为了清晰地描述FLOPs与性能的帕累托前沿而提出的。ELUE由三个任务(情感分析、自然语言推理和释义)的六个数据集组成。ELUE有四个轨道，参数数截止为40M, 55M, 70M和110M。用于评估的度量是ELEU分数，它计算在不同FLOPs下相对于基线(ElasticBERT)的平均性能优势。</p>
<h2 id="2-3-method"><a href="#2-3-method" class="headerlink" title="2.3 method"></a>2.3 method</h2><h3 id="2-3-1-weight-sharing"><a href="#2-3-1-weight-sharing" class="headerlink" title="2.3.1 weight sharing"></a>2.3.1 weight sharing</h3><p>权重共享是基于这样的假设，即大规模模型，如Transformer是过度参数化的。权重共享通过重复使用相同的参数进行多次计算，提供了一种解耦计算和参数的方法。权重共享可以减少推理内存占用和参数数量，因此是内存和存储高效的。</p>
<p><strong>编码器-解码器共享</strong>在用于神经机器翻译(NMT)的Transformer模型中，有一个编码器用于将输入编码为隐藏表示，一个解码器用于将其解码为目标语言。捆绑变压器共享Transformer编码器和解码器的权重，捆绑变压器的结果与香草变压器相当。Rothe<u>利用预训练语言模型检查点来初始化序列到序列模型。</u>他们用共享的编码器和解码器进行实验，以减少内存占用。</p>
<p><strong>层共享</strong>编码器和解码器都是Transformer层的堆栈。因此，在Transformer中共享权重的一个简单而直接的方法是在所有Transformer层之间共享它们。Dabre在NMT的所有Transformer层上共享权重，性能下降最小。Universal Transformer在所有层之间共享权重，允许使用动态停机机制进行循环计算，并取得了比普通Transformer更好的性能。ALBERT将这一思想引入到自然语言处理(NLU)的预训练语言模型中。虽然它不能减少计算开销，并且对性能有不可避免的负面影响，但这种设计为存储模型节省了高达95%的磁盘空间，这对于在存储有限的移动设备上部署可能至关重要。<strong>Takase系统地研究了跨层共享权重的策略。他们的目标不是为所有层使用一个Transformer层的权重，而是探索对于N层(M &lt; N)使用M层参数的最佳方法。</strong>Reid引入了一种名为“三明治式”参数共享的策略，该策略共享中心层的权重，同时使第一层和最后一层独立。</p>
<h3 id="2-3-2-low-rank-factorization"><a href="#2-3-2-low-rank-factorization" class="headerlink" title="2.3.2 low-rank factorization"></a>2.3.2 low-rank factorization</h3><p>神经网络中的<u>权重矩阵通常是低秩的，表明模型权重存在冗余。</u>因此，一个自然的想法是将权重矩阵分解为两个或更多更小的矩阵来保存参数。低秩分解的一种常用技术是奇异值分解(SVD)。对于一个矩阵a∈Rm×n，存在a = UΣV T，其中r≤min {m, n}是a的秩;U∈Rm×r，V∈Rn×r是两个正交矩阵;Σ∈Rr×r是只有a的非零奇异值的对角矩阵，从而可以有效地将空间复杂度从O(mn)降低到O(mr +rn)，提高模型的存储效率。</p>
<p><strong>分解线性层</strong>低秩因子分解可以应用于任何线性层。Grachev对LSTM语言模型的权重进行了分解。之后，Winata等在语言建模任务中的LSTM单元和预训练的LSTM语言模型ELMo中利用SVD。这是对压缩预训练语言模型的最早尝试之一。Ma et al.提出了一种新的自注意力模块，即多线性注意力，作为Transformer中标准多头注意力模块的替代品。他们使用块项张量分解(BTD, Lathauwer 2008)来分解多头注意力。他们的结果显示了与vanilla Transformer相当的性能，同时具有参数效率。Noach提出了一种两阶段的方法来压缩预训练语言模型。第一阶段，利用SVD对预训练语言模型中的权重矩阵进行分解。然后，在第二阶段，他们微调或使用知识蒸馏来细化权重。Chen等人通过利用数据分布的先验知识，提出了数据感知低秩压缩(DRONE)。他们不是最小化权重矩阵的重构误差，而是最小化输出的近似误差。DRONE的性能优于SVD。此外，作为SVD的替代方法，<u>Kronecker分解保留了矩阵的秩，在BERT和GPT-2的压缩中表现出改进。</u></p>
<p><strong>分解embedding</strong>ALBERT对嵌入层使用分解，由于其高输入和输出维数而具有冗余参数。由于Transformer的力量主要来自于它的上下文学习能力，token嵌入层中的参数效率不高。直观上讲，通过分解嵌入矩阵来减少它们是有意义的。Reid提出了自关注因式嵌入(SAFE)，通过在线性投影的基础上增加一个小的自关注层来获得更好的性能。</p>
<h2 id="2-3-3-pruning"><a href="#2-3-3-pruning" class="headerlink" title="2.3.3 pruning"></a>2.3.3 pruning</h2><p>剪枝旨在从神经网络中删除不重要的权重，以实现存储、内存效率，有时还包括计算和时间效率，同时保持模型性能。剪枝方法中有两个关键要素:(1)<u>剪枝单元是要从模型中删除的原子单元</u>;它可以是单个权重(非结构化剪枝)、一个注意力头甚至是一个Transformer层(结构化剪枝)。(2)<u>显著性分数是做出剪枝决策的标准</u>。根据它是否使用梯度以及它使用的梯度阶数，我们可以将修剪方法分为零阶(仅考虑权重大小)、一阶和二阶方法。我们在表1中总结了一些具有代表性的剪枝方法。</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/ShuaiLv-JNU/blogImage/main/img/202307182217268.png"></p>
<p><strong>非结构化修剪</strong>非结构化修剪通过将相应的权重设置为0来删除神经网络中“不重要”的连接。剪枝后，权值矩阵往往变得稀疏。为了利用稀疏矩阵的特性来实现计算和存储效率，专门的硬件(例如Nvidia A100中的稀疏张量内核(Mishra et al. 2021))和软件(例如Py-Torch sparseAPI2))是必要的。参见，Luong和Manning(2016)使用基于量的修剪和<u>再训练</u>来压缩NMT的RNN模型。在修剪后，See, Luong和Manning(2016)<u>继续对修剪后的网络进行微调</u>，以获得更好的性能。Narang et al.(2017)在训练过程中<u>逐渐修剪</u>RNN模型。随着训练步数的增加，<u>剪枝的幅度阈值逐渐增加</u>。Wang等人(2020b)首先对NMT模型<u>进行幅度修剪和再训练</u>，然后<u>恢复</u>修剪后的pa参数，<u>重新训练整个网络</u>，以获得比原始模型更好的性能。Zhang和Stadie(2020)提出了一种基于雅可比矩阵谱的一次剪枝技术。与迭代剪枝方法不同，one-shot剪枝技术<u>只对网络进行一次剪枝，然后使用标准训练来训练稀疏网络</u>。</p>
<p>最近的一些工作以<strong>迁移学习</strong>为目标，因为它已经成为NLP中的新标准范式。Gordon, Duh和Andrews(2020)旨在揭示剪枝如何影响迁移学习。他们发现，<u>低水平的修剪(30%-40%)根本不会影响预训练损失或迁移到下游任务。然而，进一步的剪枝对预训练和迁移学习都有负面影响</u>。高水平的剪枝甚至会阻止模型拟合下游数据集。Sanh、Wolf和Rush(2020)声称，量级剪枝对于迁移学习是次优的。他们提出，<em>运动剪枝</em>是一种简单的一阶方法，用于对预训练语言模型进行微调。<u>他们不是保留目前远离零的权重，而是保留微调期间<strong>正在</strong>远离零的权重(即获得更大的量级)</u>，为修剪BERT实现更好的性能。Guo、Rush和Kim(2021)提出了diff剪枝，通过学习<strong>一个特定于任务</strong>的“diff”向量来扩展原始预训练参数。特定于任务的“diff”向量使用L0正则化(Louizos, Welling和Kingma 2018)进行训练，以鼓励稀疏性。通过只更新0.5%的参数，diff剪枝实现了与微调整个网络相似的性能。</p>
<p><strong>结构化剪枝</strong>结构化剪枝从模型中删除权重块、行、注意力头或层。与非结构化剪枝相比，它通常可以在不需要专门硬件或软件的情况下实现加速和内存减少。Narang, Undersander和Diamos(2017)将rnn的渐进修剪(Narang等人，2017)扩展到结构化修剪。他们首先将权重划分为块，然后使用组套索正则化(Yuan and Lin 2006)在一层中修剪权重块，以创建权重矩阵中的零块。Michel, Levy, and Neubig(2019)和Voita等人(2019)发现Transformer中的多头注意力具有冗余。这两项工作都使用一阶方法从Transformer中移除注意力头。随后，Fan、Grave和Joulin(2020)提出了一种名为LayerDrop的结构化dropout策略。在训练Transformer时，对每一层应用随机dropout。一次性训练后，模型可以按需剪枝，以达到目标推理速度。SNIP (Lin等人，2020)去除残余连接中不重要的非线性项，其幅度低于阈值。Lagunas等人(2021)引入了一种块修剪方法，通过考虑任何大小的块来扩展结构化方法。他们将这种结构集成到运动剪枝中(Sanh、Wolf和Rush 2020)，并发现这种方法可以自动学习剪枝出Transformer中的全部组件，例如注意力头。Xia, Zhong, and Chen(2022)提出了CoFi，这是一种<u>联合修剪粗粒度单元(如层)和细粒度单元(如注意头和隐藏单元)的修剪方法</u>。CoFi还引入了蒸馏损失，以进一步提高其性能。</p>
<p><strong>彩票假说</strong>Frankle和Carbin(2019)提出了“彩票假说”:密集的、随机初始化的前馈网络<strong>包含子网络</strong>(中奖彩票)——在单独训练时——在类似的迭代次数下达到与原始网络相当的测试精度。相反，即使从头开始训练(只要用相同的随机权重初始化)，一张“中奖彩票”总是可以学习得更好。在此之后，Chen等人(2020)通过迭代幅度修剪在BERT上验证彩票假设。他们发现，在预训练任务(即掩码语言建模，MLM)上发现的子网络普遍迁移到下游任务，而在下游任务上发现的子网络则不会。Prasanna, Rogers和Rumshisky(2020)也用BERT验证了彩票假设，包括量级和结构化修剪。他们发现，即使是BERT中最差的子网仍然是高度可训练的，这表明BERT的权重可能具有相对较低的冗余度。这似乎与之前在过度参数化模型上的发现一致(Nakkiran et al. 2020)。</p>
<h3 id="2-3-4-quantization"><a href="#2-3-4-quantization" class="headerlink" title="2.3.4 quantization"></a>2.3.4 quantization</h3><p>量化旨在通过减少模型权重中的比特数(即精度)来压缩神经网络，提高存储、内存、计算和时间效率(在大多数硬件上)。通常，量化可以进一步分为<strong>训练后量化(post-training, PTQ)和量化感知训练(quanti- aware training, QAT)<strong>。PTQ重新调整训练模型的权重，而QAT将舍入误差引入训练过程。由于PTQ的性能下降较大，大多数压缩NLP模型的工作一致使用</strong>QAT</strong>，以达到与全精度模型相当的性能。</p>
<p><strong>8位量化</strong>从全精度浮点数(FP32)到8位整数(INT8)的量化模型是一种经典设置，因为使用INT8可以比FP32更快地计算包括矩阵乘法在内的操作，特别是在CPU上。Zafrir等人(2019)使用对称线性量化(Jacob等人，2018)动态量化INT8的权重和激活。他们还探讨了BERT的量化感知训练(QAT)。他们使用<em>假量化</em><em>(Jacob</em>等人，2018)在训练阶段将量化误差引入模型以模拟舍入效果。他们使用直通式估计器(STE) (Ben-gio, L ‘ leonard, and Courville 2013)来估计不可微伪量化的梯度。他们发现动态训练后量化稍微损害了下游性能，而QAT达到了与原始模型相当的性能。同样，Prato, Charlaix, and Rezagholizadeh(2020)将QAT和STE用于变形金刚的神经机器翻译，并获得了与原始模型相似的结果。I-BERT (Kim et al. 2021)通过利用BERT中的非线性操作(例如GELU, Softmax和layernorm)的轻量级整数近似方法，消除了激活中的浮点计算。所得到的I-BERT模型能够进行纯粹的INT8推理，因此具有更好的加速比。</p>
<p><strong>低比特量化</strong>最近的工作旨在将量化推向更低的精度。低比特量化面临更多挑战，包括优化难度，以及缺乏模型表达能力。Shen等人(2020)提出了一种<strong>群智能量化方案</strong>，并使用基于二阶hessian的混合精度方法(Dong et al. 2019)将BERT量化到2位。他们声称，每个神经元对应的权重可以位于不同的实数范围内。例如，对于一个多头自注意力模块，他们将权重矩阵划分为12组，相对于每个注意力头。然后他们进一步划分每个组，总共有128个子组，每个子组都有自己的量化范围。GOBO (Zadeh et al. 2020)将权重分为两组-高斯和<em>离</em>群值，其中前者量化为3位，后者仍然是全精度浮点数(FP32)。TernaryBERT (Zhang et al. 2020)结合了BERT中不同成分的不同粒度的近似感知和损失感知三元化(即仅使用{−1,0,1}作为权重)方法。他们进一步增加了知识蒸馏，以提高QAT的性能。Bai等人(2021)观察到，直接训练时，由于其损失格局，从三元网络到二元网络的性能有很大下降。他们提出了三元权重拆分，通过将一个半大小的三元网络拆分为两个二元网络来初始化BinaryBERT。初始化的网络继承了良好的性能，可以进一步微调而没有优化困难。Tao等人(2022)分析了量化在生成式LMs(例如，GPT-2, BART)上效果较差的原因。他们得出的结论是，<strong>容量减少和权重分布变化导致的同质词嵌入是导致失败的原因。他们提出了一种token级别的对比蒸馏和一种模块级的动态缩放机制来缓解这两个问题。</strong></p>
<h3 id="2-3-5-knowledge-distillation"><a href="#2-3-5-knowledge-distillation" class="headerlink" title="2.3.5 knowledge distillation"></a>2.3.5 knowledge distillation</h3><p>知识蒸馏(Hinton et al. 2015)是一种广泛使用的技术，用于将知识从大模型(教师)转移到小模型(学生)，以实现所有类型的效率。KD通常需要<strong>设计一个损失函数来最小化输出的距离或学生和老师之间的中间特征</strong>。如图1所示，我们总结了最近在蒸馏NLP模型的工作中使用的损失函数的设计。基于损失函数的设计，我们可以进一步将方法分为基于逻辑的KD、基于特征的KD、动态目标的KD和模块替换。</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/ShuaiLv-JNU/blogImage/main/img/202307182238152.png"></p>
<p><strong>基于logit的KD方法</strong>是继Hinton等人(2015)之后，首次尝试将大型预训练语言模型提炼成较小的预训练语言模型，以提高其效率。基于对数的KD使用KL散度或均方误差(MSE)来最小化学生和教师之间的对数。Tang等人(2019)在特定任务设置中将微调的BERT提炼成BiLSTM模型。所得到的BiLSTM在没有KD训练的情况下比其对应物性能要好得多。DistilBERT (Sanh等人，2019)在屏蔽语言建模(MLM)任务的预训练设置中提取BERT。损失是三个组成部分的组合:原始传销损失、余弦距离和KL散度。蒸馏后，模型可以进行微调，并执行下游任务。Turc et al.(2019)探索了初始化对学生的影响。他们发现用传销预训练的学生BERT优于随机初始化和截断教师(Sanh等人，2019;Sun et al. 2019)在用于初始化学生模型时。Liang等人(2021)使用MixUp (Zhang等人2018)进行数据增强以提取BERT。</p>
<p><strong>基于特征的KD</strong>不是只使用最终输出，基于特征的KD旨在对齐教师和学生之间的中间特征。PKD (Sun et al. 2019)引入了层表示之间的MSE损失。如图1(c)和(d)所示，他们提出了两种策略:一种是将学生与教师的最后几层(PKD-Last)对齐，另一种是每2层学习教师的表征(PKD-Skip)。后一种策略在实验中的表现稍好一些。Aguilar等人(2020)也提出了类似的技术。在PKD的基础上，TinyBERT(焦等人，2020)进一步引入了一种注意力损失，旨在将教师和学生之间的注意力矩阵分层对齐，如图1(e)所示。TinyBERT还表明，在预训练和<strong>微调阶段进行KD</strong>可以提高KD的性能。类似地，MiniLM (Wang等人，2020a, 2021)将注意力矩阵和值-值比例的点积(即值关系损失，如图1(f)所示)对齐。新增的特征对注意力矩阵(即queries-keys scaled - dot-product)进行了补充，并允许多头自注意力的完全转移。Wu、Wu和Huang(2021)提出了一个<strong>多教师蒸馏框架</strong>，该框架使用多个教师的中间特征和软标签来提炼学生并获得更好的表现。DynaBERT (Hou et al. 2020)<strong>使用分层KD损失将教师提取到具有不同宽度和深度的子网络的学生模型中。因此，相同的模型可以在具有不同计算预算的各种设备上使用。</strong>MobileBERT (Sun et al. 2020)重新设计了一个适用于移动设备的BERT架构。除了分层特征蒸馏(Sun et al. 2019)和注意力蒸馏(焦 et al. 2020)之外，他们还通过逐层蒸馏模型(而不是全部)引入了<strong>渐进式知识转移机制</strong>。Liu et al. (2022)利用token和span水平上的结构特征来使学生与教师保持一致。</p>
<p>KD的一个特例是伯特-忒修斯 (Xu et al. 2020)。如图1(b)所示，伯特-忒修斯没有使用任何知识转移损失来最小化学生与教师之间的距离。相反，<strong>他们冻结教师模块，并通过用学生模块随机替换教师模型中的一些模块来训练一个混合模型</strong>。他们进一步设计了一个线性调度器来增加替换的概率，以弥合训练和推理之间的差距。在此之后，稀疏渐进蒸馏(Huang等人，2022)使用分层KD迭代地修剪学生模块，同时以固定的概率将教师模型中的每个模块随机替换为相应的学生模块。在目标稀疏度被击中后，替换率逐步增加到1。<strong>该方法结合了基于特征的KD、模块替换和剪枝</strong>，在GLUE上实现了超级教师的性能(Wang等，2019b)。</p>
<p>在传统的KD中，教师作为一个静态的目标供学生匹配，在精馏过程中不进行任何更新。然而，这可能是次优的，因为教师不知道学生或其将知识传递给学生的目标。ProKT (Shi et al. 2020)通过将训练目标分解为具有近似镜像下降的局部中间目标，将教师模型的监督信号投射到学生的参数空间中(Beck和Teboulle 2003)。Zhou、Xu和McAuley(2022)提出了一个更简单的元学习框架，使教师能够适应更好的知识转移。经过几个训练步骤后，学生将在“测验”集上进行评估，并向教师提供<strong>反馈</strong>。它的一阶变体可以进一步提高训练速度并减少内存占用(Ma et al. 2022)。</p>
<h3 id="2-3-6-提前退出"><a href="#2-3-6-提前退出" class="headerlink" title="2.3.6 提前退出"></a>2.3.6 提前退出</h3><p>提前退出(EE)并不会减少模型的大小(参数总数)。相反，EE通过基于某些标准在特定层终止推理来加速模型推理。虽然它没有使模型更小，但它可以减少计算量并实现加速。提前退出将内部分类器(通常是简单的线性层)插入到一个大型网络中，作为提前退出的触发器。早退出方法的关键要素是退出标准。退出标准有三种类型:置信度估计、内部集成和学习退出。我们在表2中总结了退出标准。</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/ShuaiLv-JNU/blogImage/main/img/202307182246532.png"></p>
<p>置信度估计以前在计算机视觉方面的工作(Park et al. 2015;Teerapittayanon、McDanel和Kung 2016;Kaya, Hong, and Dumitras 2019)定义了一个指标作为预测信心的代理。如果置信度在早期层达到阈值，则推断可以提前退出。然后将这个想法应用于预训练的LMs (Xin et al. 2020)。对于每个Transformer层，在Transformer层之后插入一个线性内部分类器(IC)。在进行推理时，当IC输出一个熵低于阈值的预测概率时，模型提前退出。RightTool中提出了类似的方法(Schwartz et al. 2020)。使用温度校准的最大类别概率作为置信度。FastBERT (Liu et al. 2020)将输出的最终分类器提炼为早期的分类器，以获得更好的性能。随后，RomeBERT (Geng et al. 2021)提出了梯度正则化来简化KD。SkipBERT (Wang et al. 2022)将较低的BERT层替换为预先计算的文本块表示，并对较高的层使用基于置信度的提前退出以实现最大加速。</p>
<p>内部集成置信度估计的一个弱点是计算利用率差。当内部分类器的置信度不满足退出标准时，所有相关的计算都将失效。重用前几层的结果来提高提前退出的资格可能是一个有希望的方向。内部集成方法考虑多个内部分类器的输出和预测，以做出更好的决策。这类似于集成学习，只是它是在单个模型内。</p>
<p>内部集成的第一部作品PABEE (Zhou等人，2020)比较了训练中的过拟合和推理中的过度思考，并适应了推理的早期停止。在进行推理时，一旦多个连续的内部分类器做出相同的预测，模型就会退出。阈值，即耐心，是一个可以调整的超参数，以实现精度和速度之间的不同权衡。除了性能和效率的提高外，PABEE还具有更好的对抗鲁棒性，这归功于内部集合的集合效应。Sun等人(2021)提出了一种多样性损失，鼓励集成电路具有多样化的概率分布。然后，他们使用投票机制在内部集成分类器。每个IC在最终预测中都有一票。当一个类别累积了足够的选票时，该模型将退出。Lee-BERT (Zhu 2021)通过相互提炼IC预测来促进一致性。然后，它遵循PABEE的基于耐心的策略来决定何时退出。Liao et al.(2021)为内部合奏引入了更精细的机制。他们首先训练“模仿学习者”(imitation learner)，这是一种线性层，根据已经计算好的隐藏状态预测未来层的隐藏状态。PCEE-BERT (Zhang et al. 2022)将基于耐心的退出与置信度估计相结合，并在多个层处于时终止推理自信。</p>
<p>学习退出其他作品使用一种基于学习的方法来做出退出的决定。BERxiT (Xin et al. 2021)训练一个线性学习退出(LTE)模块来预测当前IC预测是否正确。CAT (Schuster et al. 2021)提出了一个“元一致性分类器”来预测当前IC预测是否与最终分类器匹配，并在一致性分类器预测的符合性水平高于阈值时退出。</p>
<h3 id="2-3-7-令牌跳过"><a href="#2-3-7-令牌跳过" class="headerlink" title="2.3.7 令牌跳过"></a>2.3.7 令牌跳过</h3><p>与提前退出类似，跳过代币可以动态地加速PLM，而不减少其规模。一般的想法是根据它们的重要性跳过一些代币给更高的层。这些方法的总结如表3所示。</p>
<p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/ShuaiLv-JNU/blogImage/main/img/202307182248402.png"></p>
<p>PoWER-BERT (Goyal等人，2020)根据每个令牌收到的关注在每个Transformer层之间丢弃一部分to-kens。通过与原始损失函数联合优化软掩膜层的稀疏性来学习在每一层(即<em>调度</em>*)*丢弃的token数量。这种方法获得了更好的精度-时间权衡的帕累托曲线。TR-BERT (Ye et al. 2021)引入了一种动态机制，用于做出跳过代币的决策。它通过强化学习进行训练，奖励可以提高分类器的置信度，并惩罚保留token的数量。与PoWER-BERT不同，被跳过的令牌被转发到最后一层，而不是被删除。长度自适应变压器(LAT, Kim和Cho 2021)引入了LengthDrop，它在预训练期间随机跳过令牌，以减轻预训练和微调之间的差距。采用进化搜索算法对LAT调度进行搜索。LTP (Kim等人，2022)为每个Transformer层学习一个阈值。LTP并没有按照计划丢弃特定数量的令牌，而是简单地丢弃显著性分数(收到的关注)低于学习阈值的令牌。Transkimmer (Guan et al. 2022)添加了一个skim预测器模块，由一个小的MLP和Gumbel-Softmax在每一层之前重新参数化组成。skim预测器输出一个掩码，决定是否丢弃一个token。它还采用了skim损失，以优化跳过的token与总token数量的比例，以鼓励稀疏性。</p>
<h1 id="3-未来方向"><a href="#3-未来方向" class="headerlink" title="3.未来方向"></a>3.未来方向</h1><p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/ShuaiLv-JNU/blogImage/main/img/202307182249972.png"></p>
<p>最近的作品(Stanton等人，2021;Xu et al. 2021a)对模型压缩和加速的可解释性提出了质疑。同时，最近的工作(Du et al. 2021;Xu et al. 2021a)报告了模型压缩对鲁棒性的负面影响。<strong>可解释和鲁棒的压缩方法对于模型压缩和加速的应用可能很重要。</strong>此外，可解释和稳健的压缩减少了重新评估压缩模型的工作量，因此在生产中是可靠和可预测的(Stanton等人，2021;Xu et al. 2021a)。</p>
<p>目前的压缩和加速方法在很大程度上仍然依赖于人类的启发式方法来实现良好的性能。例如，<strong>知识蒸馏通常需要精心设计的损失函数;剪枝依赖于显著性分数;权重共享和低秩因子分解涉及到指定模块进行共享或因子分解的专业知识</strong>。<strong>一个有希望的方向可能是将元学习(Finn, Abbeel和Levine 2017)或神经架构搜索(Liu, Simonyan和Yang 2019)应用于模型压缩和加速</strong>，以最大限度地减少对超参数和人类设计的需求。</p>

            </div>

            
                <div class="post-copyright-info">
                    <div class="article-copyright-info-container">
    <ul>
        <li><strong>Title:</strong> 2023AAAI-A Survey on Model Compression and Acceleration for Pretrained Language Models</li>
        <li><strong>Author:</strong> Shuai Lv</li>
        <li><strong>Created at:</strong> 2023-07-18 21:29:41</li>
        
            <li>
                <strong>Updated at:</strong> 2023-07-18 22:51:11
            </li>
        
        <li>
            <strong>Link:</strong> https://blogls.top/2023/07/18/2023AAAI-A-Survey-on-Model-Compression-and-Acceleration-for-Pretrained-Language-Models/
        </li>
        <li>
            <strong>License:</strong> This work is licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">CC BY-NC-SA 4.0</a>.
        </li>
    </ul>
</div>

                </div>
            

            
                <ul class="post-tags-box">
                    
                        <li class="tag-item">
                            <a href="/tags/LLM/">#LLM</a>&nbsp;
                        </li>
                    
                </ul>
            

            <div class="recommended-article">
  <div class="recommended-article-header">
    <i aria-hidden="true"></i><span>推荐阅读</span>
  </div>
  <div class="recommended-article-group"><a class="recommended-article-item" href="/2023/06/20/Efficient-AI-Google研究院综述-2023/" title="Efficient AI-Google研究院综述-2023" rel="bookmark">
  <img src="/images/wallhaven-wqery6-light.webp" alt="Efficient AI-Google研究院综述-2023">
  <span class="title">Efficient AI-Google研究院综述-2023</span>
</a><a class="recommended-article-item" href="/2023/05/28/2022-Enable-Deep-Learning-on-Mobile-Devices-Methods-Systems-and-Applications-韩松-CCF-B/" title="2022|Enable Deep Learning on Mobile Devices: Methods, Systems, and Applications|韩松|CCF-B" rel="bookmark">
  <img src="/images/wallhaven-wqery6-light.webp" alt="2022|Enable Deep Learning on Mobile Devices: Methods, Systems, and Applications|韩松|CCF-B">
  <span class="title">2022|Enable Deep Learning on Mobile Devices: Methods, Systems, and Applications|韩松|CCF-B</span>
</a><a class="recommended-article-item" href="/2023/06/27/Efficient-LLM/" title="Efficient LLM" rel="bookmark">
  <img src="/images/wallhaven-wqery6-light.webp" alt="Efficient LLM">
  <span class="title">Efficient LLM</span>
</a></div>
</div>

            
                <div class="article-nav">
                    
                    
                        <div class="article-next">
                            <a class="next"
                            rel="next"
                            href="/2023/07/17/Diffusion%20model%20Basic(1)/"
                            >
                                <span class="title flex-center">
                                    <span class="post-nav-title-item">Diffusion model Basic(1)</span>
                                    <span class="post-nav-item">Next posts</span>
                                </span>
                                <span class="right arrow-icon flex-center">
                                    <i class="fa-solid fa-chevron-right"></i>
                                </span>
                            </a>
                        </div>
                    
                </div>
            


            
                <div class="comment-container">
                    <div class="comments-container">
    <div id="comment-anchor"></div>
    <div class="comment-area-title">
        <i class="fa-solid fa-comments"></i>&nbsp;Comments
    </div>
    

        
            
    <div id="gitalk-container"></div>
    <script data-pjax
            src="//cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js"></script>
    <script data-pjax>

        function loadGitalk() {
            let __gitalk__pathname = decodeURI(location.pathname);
            const __gitalk__pathnameLength = __gitalk__pathname.length;
            const __gitalk__pathnameMaxLength = 50;
            if (__gitalk__pathnameLength > __gitalk__pathnameMaxLength) {
                __gitalk__pathname = __gitalk__pathname.substring(0, __gitalk__pathnameMaxLength - 3) + '...';
            }

            try {
                Gitalk && new Gitalk({
                    clientID: 'ca3b187a2eb63dfd2d20',
                    clientSecret: 'e96896908ba4dc10bb61a89de608ea3a0ce32013',
                    repo: 'Gitalk',
                    owner: 'ShuaiLv-JNU',
                    admin: ['ShuaiLv-JNU'],
                    id: __gitalk__pathname,
                    language: 'en'
                }).render('gitalk-container');

            } catch (e) {
                window.Gitalk = null;
            }
        }

        if ('true') {
            const loadGitalkTimeout = setTimeout(() => {
                loadGitalk();
                clearTimeout(loadGitalkTimeout);
            }, 1000);
        } else {
            window.addEventListener('DOMContentLoaded', loadGitalk);
        }
    </script>



        
    
</div>

                </div>
            
        </div>

        
            <div class="toc-content-container">
                <div class="post-toc-wrap">
    <div class="post-toc">
        <div class="toc-title">On this page</div>
        <div class="page-title">2023AAAI-A Survey on Model Compression and Acceleration for Pretrained Language Models</div>
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-Intro"><span class="nav-text">1. Intro</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-1-%E6%A0%B8%E5%BF%83%E9%97%AE%E9%A2%98"><span class="nav-text">1.1 核心问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-2-abstract"><span class="nav-text">1.2 abstract</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-3-introduction"><span class="nav-text">1.3 introduction</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-detail"><span class="nav-text">2. detail</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-metric"><span class="nav-text">2.1 metric</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-benchmark"><span class="nav-text">2.2 benchmark</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-method"><span class="nav-text">2.3 method</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-1-weight-sharing"><span class="nav-text">2.3.1 weight sharing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-2-low-rank-factorization"><span class="nav-text">2.3.2 low-rank factorization</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-3-pruning"><span class="nav-text">2.3.3 pruning</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-4-quantization"><span class="nav-text">2.3.4 quantization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-5-knowledge-distillation"><span class="nav-text">2.3.5 knowledge distillation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-6-%E6%8F%90%E5%89%8D%E9%80%80%E5%87%BA"><span class="nav-text">2.3.6 提前退出</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-7-%E4%BB%A4%E7%89%8C%E8%B7%B3%E8%BF%87"><span class="nav-text">2.3.7 令牌跳过</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-%E6%9C%AA%E6%9D%A5%E6%96%B9%E5%90%91"><span class="nav-text">3.未来方向</span></a></li></ol>

    </div>
</div>
            </div>
        
    </div>
</div>


                

            </div>
            
            

        </div>

        <div class="main-content-footer">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info">
            &copy;
            
              <span>2023</span>
              -
            
            2023&nbsp;&nbsp;<i class="fa-solid fa-heart fa-beat" style="--fa-animation-duration: 0.5s; color: #f54545"></i>&nbsp;&nbsp;<a href="/">Shuai Lv</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv" class="busuanzi_container_site_uv">
                        VISITOR COUNT&nbsp;<span id="busuanzi_value_site_uv" class="busuanzi_value_site_uv"></span>
                    </span>
                
                
                    <span id="busuanzi_container_site_pv" class="busuanzi_container_site_pv">
                        TOTAL PAGE VIEWS&nbsp;<span id="busuanzi_value_site_pv" class="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="theme-info info-item">
            <span class="powered-by-container">POWERED BY <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" href="https://hexo.io">Hexo</a></span>
                <br>
            <span class="theme-version-container">THEME&nbsp;<a class="theme-version" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.1.4</a>
        </div>
        
        
        
            <div id="start_div" style="display:none">
                2023/5/28 22:00:00
            </div>
            <div>
                Blog up for <span class="odometer" id="runtime_days" ></span> days <span class="odometer" id="runtime_hours"></span> hrs <span class="odometer" id="runtime_minutes"></span> Min <span class="odometer" id="runtime_seconds"></span> Sec
            </div>
        
        
            <div class="customize-info info-item">ChatGPT is all you need.</div>
        
        
            <script async data-pjax>
                try {
                    function odometer_init() {
                    const elements = document.querySelectorAll('.odometer');
                    elements.forEach(el => {
                        new Odometer({
                            el,
                            format: '( ddd).dd',
                            duration: 200
                        });
                    });
                    }
                    odometer_init();
                } catch (error) {}
            </script>
        
        
        
    </div>  
</footer>
        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="article-tools-list">
        <!-- TOC aside toggle -->
        
            <li class="right-bottom-tools page-aside-toggle">
                <i class="fa-regular fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="go-comment">
                <i class="fa-regular fa-comments"></i>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-side-tools-container">
        <div class="side-tools-container">
    <ul class="hidden-tools-list">
        <li class="right-bottom-tools tool-font-adjust-plus flex-center">
            <i class="fa-regular fa-magnifying-glass-plus"></i>
        </li>

        <li class="right-bottom-tools tool-font-adjust-minus flex-center">
            <i class="fa-regular fa-magnifying-glass-minus"></i>
        </li>

        <li class="right-bottom-tools tool-expand-width flex-center">
            <i class="fa-regular fa-expand"></i>
        </li>

        <li class="right-bottom-tools tool-dark-light-toggle flex-center">
            <i class="fa-regular fa-moon"></i>
        </li>

        <!-- rss -->
        

        

        <li class="right-bottom-tools tool-scroll-to-bottom flex-center">
            <i class="fa-regular fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="visible-tools-list">
        <li class="right-bottom-tools toggle-tools-list flex-center">
            <i class="fa-regular fa-cog fa-spin"></i>
        </li>
        
            <li class="right-bottom-tools tool-scroll-to-top flex-center">
                <i class="arrow-up fas fa-arrow-up"></i>
                <span class="percent"></span>
            </li>
        
        
    </ul>
</div>

    </div>

    <div class="image-viewer-container">
    <img src="">
</div>


    


</main>



<script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/js/utils.js"></script><script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/js/main.js"></script><script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/js/layouts/navbarShrink.js"></script><script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/js/tools/scrollTopBottom.js"></script><script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/js/tools/lightDarkSwitch.js"></script>




    <script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/js/tools/codeBlock.js"></script>



    <script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/js/layouts/lazyload.js"></script>



    <script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/js/tools/runtime.js"></script>
    <script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/js/layouts/odometer.min.js"></script>
    <link rel="stylesheet" href="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/assets/odometer-theme-minimal.css">



  <script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/js/libs/Typed.min.js"></script>
  <script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/js/plugins/typed.js"></script>



    <script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/js/libs/mermaid.min.js"></script>
    <script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/js/plugins/mermaid.js"></script>



    <script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/js/libs/minimasonry.min.js"></script>
    <script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/js/plugins/masonry.js"></script>


<div class="post-scripts pjax">
    
        <script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/js/tools/tocToggle.js"></script><script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/js/libs/anime.min.js"></script><script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/js/layouts/toc.js"></script><script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/js/plugins/tabs.js"></script>
    
</div>


    <script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/js/libs/pjax.min.js"></script>
<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax',
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            Global.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            Global.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            Global.refresh();
        });
    });
</script>




    <div id="aplayer"></div>
<script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/js/libs/APlayer.min.js"></script>
<script src="//npm.elemecdn.com/hexo-theme-redefine@2.1.4/source/js/plugins/aplayer.js"></script>

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"jsonPath":"/live2dw/assets/tororo.model.json"},"display":{"superSample":2,"width":200,"height":400,"position":"left","hOffset":30,"vOffset":30},"mobile":{"show":true},"react":{"opacityDefault":0.7,"opacityOnHover":0.2},"dialog":{"enable":true,"hitokoto":true},"log":false});</script></body>
</html>
