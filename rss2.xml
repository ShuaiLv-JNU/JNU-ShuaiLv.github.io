<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>乐愚良</title>
    <link>http://blogls.top/</link>
    
    <atom:link href="http://blogls.top/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>丈夫处世兮，立功名；立功名兮，慰平生</description>
    <pubDate>Wed, 31 May 2023 15:45:18 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>极客时间-Pytorch-图像分类模型</title>
      <link>http://blogls.top/2023/05/31/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4-Pytorch-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/</link>
      <guid>http://blogls.top/2023/05/31/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4-Pytorch-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/</guid>
      <pubDate>Wed, 31 May 2023 15:21:03 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;1-图像分类原理&quot;&gt;&lt;a href=&quot;#1-图像分类原理&quot; class=&quot;headerlink&quot; title=&quot;1.图像分类原理&quot;&gt;&lt;/a&gt;1.图像分类原理&lt;/h2&gt;&lt;p&gt;模型会接收一张图片，然后会输出一组概率，分别是该图片为 Logo 的概率与该图片为其他图片的</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="1-图像分类原理"><a href="#1-图像分类原理" class="headerlink" title="1.图像分类原理"></a>1.图像分类原理</h2><p>模型会接收一张图片，然后会输出一组概率，分别是该图片为 Logo 的概率与该图片为其他图片的概率，从而通过概率来判断这张图片是 Logo 类还是 Other 类</p><p><img lazyload="" src="/images/loading.svg" data-src="https://static001.geekbang.org/resource/image/f4/68/f4b226497cb6aae5e0dcde4f65e46a68.png?wh=1392x604" alt="img"></p><h3 id="1-1感知机"><a href="#1-1感知机" class="headerlink" title="1.1感知机"></a>1.1感知机</h3><p>其中输入的图片，将其展开后，可以获得输入 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="17.997ex" height="1.984ex" role="img" focusable="false" viewBox="0 -683 7954.6 877"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path></g><g data-mml-node="mo" transform="translate(1129.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(2185.6,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(3194.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(3638.8,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mn" transform="translate(605,-150) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(4647.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(5092,0)"><path data-c="2026" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z"></path></g><g data-mml-node="mo" transform="translate(6430.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(6875.3,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>，而模型可以看做<strong>有两个节点，每个节点都会有一个输出</strong>，分别代表着对输入为 Logo 和 Other 的判断，但这里的输出暂时还不是概率，只是模型输出的一组数值：</p><p><img lazyload="" src="/images/loading.svg" data-src="https://static001.geekbang.org/resource/image/03/29/0322747253dbbffe80a92004ea12be29.png?wh=1732x660" alt="感知机"></p>]]></content:encoded>
      
      
      <category domain="http://blogls.top/categories/Basic-of-Deep-Learning/">Basic of Deep Learning</category>
      
      
      <category domain="http://blogls.top/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/">图像分类</category>
      
      <category domain="http://blogls.top/tags/Pytorch/">Pytorch</category>
      
      <category domain="http://blogls.top/tags/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4/">极客时间</category>
      
      
      <comments>http://blogls.top/2023/05/31/%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4-Pytorch-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>2023-ICLR-Meta-prediction Model for Distillation-Aware NAS on Unseen Datasets</title>
      <link>http://blogls.top/2023/05/31/2023-ICLR-Meta-prediction-Model-for-Distillation-Aware-NAS-on-Unseen-Datasets/</link>
      <guid>http://blogls.top/2023/05/31/2023-ICLR-Meta-prediction-Model-for-Distillation-Aware-NAS-on-Unseen-Datasets/</guid>
      <pubDate>Wed, 31 May 2023 08:57:10 GMT</pubDate>
      
        
        
      <description>&lt;div class=&quot;tabs&quot; id=&quot;tab-总览&quot;&gt;&lt;ul class=&quot;nav-tabs&quot;&gt;&lt;li class=&quot;tab active&quot;&gt;&lt;a class=&quot;#总览-1&quot;&gt;题目&lt;/a&gt;&lt;/li&gt;&lt;li class=&quot;tab&quot;&gt;&lt;a class=&quot;#总览-2&quot;&gt;论文地址&lt;</description>
        
      
      
      
      <content:encoded><![CDATA[<div class="tabs" id="tab-总览"><ul class="nav-tabs"><li class="tab active"><a class="#总览-1">题目</a></li><li class="tab"><a class="#总览-2">论文地址</a></li><li class="tab"><a class="#总览-3">代码地址</a></li></ul><div class="tab-content"><div class="tab-pane active" id="总览-1"><p>未见数据集上蒸馏感知NAS的元预测模型（Top25%）</p></div><div class="tab-pane" id="总览-2"><p><a class="link" href="https://arxiv.org/pdf/2305.16948.pdf">https://arxiv.org/pdf/2305.16948.pdf <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p></div><div class="tab-pane" id="总览-3"><p><a class="link" href="https://github.com/CownowAn/DaSS">https://github.com/CownowAn/DaSS <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p></div></div></div><h2 id="1-要点"><a href="#1-要点" class="headerlink" title="1.要点"></a>1.要点</h2><ol><li>本文提出了一种新的元学习模型，称为DaSS，用于Distillation-aware Neural Architecture Search (DaNAS)。该模型可以预测给定架构在使用给定教师进行知识蒸馏时在数据集上的最终性能，而无需实际训练它。实验结果表明，该模型成功地推广到多个未见过的数据集上，大大优于现有的元-NAS方法和快速NAS基线。</li><li>与现有的方法相比，该方法具有以下优点：<ul><li>不需要为任何新组合的数据集和教师执行昂贵的搜索；<strong>（zero-shot）</strong></li><li>可以预测给定架构在使用给定教师进行知识蒸馏时在数据集上的最终性能；<strong>（预测性能）</strong></li><li>可以推广到多个未见过的数据集上。<strong>（泛化性）</strong></li></ul></li><li>该方法主要分为两个部分：元学习和预测模型。<ul><li>元学习包括两个阶段：<ul><li>对任务特定模型进行训练，以学习任务特定表示；</li><li>对元预测模型进行训练，以学习如何从任务特定表示中预测架构性能。</li></ul></li><li>预测模型包括两个部分：任务特定编码函数和元预测模型。<ul><li>任务特定编码函数将架构映射到一个向量中，并考虑了从教师到学生的参数重映射。</li><li>元预测模型使用任务特定表示来预测架构性能。</li></ul></li></ul></li><li>该方法在多个未见过的数据集上进行了验证，包括CUB、Stanford Cars、DTD、Quickdraw、CropDisease、EuroSAT、ISIC、ChestX和ImageNet-1K。实验结果表明，该方法成功地推广到多个未见过的数据集上，并且大大优于现有的元-NAS方法和快速NAS基线。</li><li>本文提出的DaSS方法仍然存在一些问题。例如，它需要一个较大的训练集来训练元预测模型，并且可能会受到噪声数据的影响。</li></ol><h2 id="2-精读"><a href="#2-精读" class="headerlink" title="2.精读"></a>2.精读</h2><h3 id="2-1-introduction"><a href="#2-1-introduction" class="headerlink" title="2.1 introduction"></a>2.1 introduction</h3><ul><li><p>蒸馏感知神经架构搜索（DaNAS）：给定一个教师架构和一个数据集，搜索一个最佳（性能、效率）的学生架构。对于DaNAS任务，需要设计一个考虑知识提炼（KD）效果的框架 ，然而，传统的NAS框架可能是次优的，因为它们根本不考虑KD组件，而是根据其评价从头开始训练的架构进行搜索。</p><blockquote><p>次优性原因：</p><p>1）对于相同的目标数据集，从教师那里提炼知识的最佳学生架构和只用ground truth标签从头学习的最佳学生架构可能是不同的。</p><p>2）即使是同一数据集，最佳的学生架构也可能取决于特定的教师。</p></blockquote></li><li><p>为了应对这样的挑战，现有的DaNAS方法使用<strong>KD损失</strong>来指导搜索过程，或者<strong>提出一个代理来评估蒸馏性能</strong>。然而，这种现有的DaNAS方法并不能通用于多个任务（数据集），需要对数据集和教师的任何组合进行训练，并可能导致过高的计算成本。因此需要一种快速和轻量级的DaNAS方法。</p></li><li><p>对于没有KD的标准NAS任务，在开发计算效率高的快速NAS方法方面已经取得了一些进展 ，例如：</p><ul><li><strong>基于元学习的可转移NAS</strong>：在多个任务中学习广义的搜索过程，使其能够通过将在元学习阶段获得的知识转移到新的任务中来适应新的未见任务，而不需要从头开始训练NAS框架。为此，元NAS方法通常利用一个<strong>任务适应性预测模型</strong>，它能迅速适应新的数据集和设备。它们在多个基准数据集和真实世界数据集以及各种设备上的表现优于基线NAS方法，在未见过的环境下，将架构搜索时间大大减少到不到几秒钟的GPU。</li><li><strong>零成本代理</strong>：提出了几个代理，可以从第一个小批量中获得，而不需要在目标数据集上完全训练架构。</li></ul></li><li><p>然而，这种快速NAS方法对于DaNAS场景来说可能是次优的，因为它们假设从头开始训练，而不是从老师那里KD，这可能会大大影响从搜索中检索出的架构的实际准确性。因此，提出了一个快速蒸馏感知元预测模型，DaSS（蒸馏感知学生搜索），用于DaNAS任务，如下：</p></li></ul><p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/ShuaiLv-JNU/blogImage/main/img/202305311824649.png"></p><ul><li>遵循之前关于元NAS的工作，我们利用元学习来学习一个预测模型，该模型可以快速适应一个未见过的目标任务。然而，我们的方法有两个主要区别 ：<ul><li>元预测模型的蒸馏意识设计。</li><li>利用已经训练好的教师的元学习方案。</li></ul></li><li>这两个方案都是为DaNAS任务优化的。首先，我们提出了一个蒸馏感知的<strong>任务编码函数</strong>，该函数考虑了参数从教师那里重新映射的学生的输出，以估计教师对蒸馏后的学生网络的实际性能的影响。其次，我们使用<strong>教师的准确性来指导基于梯度的元预测模型的适应</strong>。这使得我们能够更准确和快速地估计架构在特定教师的目标任务（数据集）上的表现。在TinyImageNet的子集和ResNet搜索空间的神经架构上元学习所提出的蒸馏感知预测模型。然后，我们在CUB、Stanford Cars、DTD、Quickdraw、CropDisease、EuroSAT、ISIC 、ChestX和ImageNet-1K等异质未见数据集上验证了其预测性能。实验结果表明，我们的元学习预测模型能够适应新的目标任务，平均在3.45（挂钟秒）内估计出一个由未见过的老师提炼出来的架构的实际性能，而无需在目标任务上直接训练。此外，在相同的数据集上 ，具有所提出的蒸馏感知元预测模型的DaNAS框架优于现有的元NAS和零成本代理。</li><li><strong>contribution</strong><ol><li>提出了一种新型的元预测模型DaSS，它可以跨数据集、架构和教师进行通用，在提炼给定教师的知识时，可以准确预测架构的性能。</li><li><strong>一种基于特定教师和参数重映射的学生架构候选人的功能嵌入的新型蒸馏感知任务编码。</strong></li><li><strong>通过引导元预测模型在目标任务上进行快速的基于梯度的单次适应，即用教师-准确率对其进行指导。</strong></li><li>通过实验验证了我们的元预测模型在多个未见的数据集上成功地估计了给定教师的学生架构的实际准确度，在预测和GT准确度之间的相关性以及端到端的DaNAS性能方面明显优于现有方法。</li></ol></li></ul><h3 id="2-2-related-work"><a href="#2-2-related-work" class="headerlink" title="2.2 related work"></a>2.2 related work</h3><p>——</p><h3 id="2-3-background"><a href="#2-3-background" class="headerlink" title="2.3 background"></a>2.3 background</h3><p>——</p><p>为了解决特定任务NAS的低效率，在多个任务上实现可转移的NAS，提出可通用的准确率预测模型（<strong>元准确率预测模型：单轮元学习后，在几秒钟内快速搜索，来适应未见过的数据集</strong>）：<mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="24.067ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 10637.5 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mo" transform="translate(550,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(939,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(1408,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msup" transform="translate(1852.7,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D403" d="M39 624V686H270H310H408Q500 686 545 680T638 649Q768 584 805 438Q817 388 817 338Q817 171 702 75Q628 17 515 2Q504 1 270 0H39V62H147V624H39ZM655 337Q655 370 655 390T650 442T639 494T616 540T580 580T526 607T451 623Q443 624 368 624H298V62H377H387H407Q445 62 472 65T540 83T606 129Q629 156 640 195T653 262T655 337Z"></path></g></g><g data-mml-node="mi" transform="translate(915,413) scale(0.707)"><path data-c="1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z"></path></g></g><g data-mml-node="mo" transform="translate(3183.2,0)"><path data-c="3B" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 85 94 103T137 121Q202 121 202 8Q202 -44 183 -94T144 -169T118 -194Q115 -194 106 -186T95 -174Q94 -171 107 -155T137 -107T160 -38Q161 -32 162 -22T165 -4T165 4Q165 5 161 4T142 0Q110 0 94 18T78 60Z"></path></g><g data-mml-node="mi" transform="translate(3627.9,0)"><path data-c="1D719" d="M409 688Q413 694 421 694H429H442Q448 688 448 686Q448 679 418 563Q411 535 404 504T392 458L388 442Q388 441 397 441T429 435T477 418Q521 397 550 357T579 260T548 151T471 65T374 11T279 -10H275L251 -105Q245 -128 238 -160Q230 -192 227 -198T215 -205H209Q189 -205 189 -198Q189 -193 211 -103L234 -11Q234 -10 226 -10Q221 -10 206 -8T161 6T107 36T62 89T43 171Q43 231 76 284T157 370T254 422T342 441Q347 441 348 445L378 567Q409 686 409 688ZM122 150Q122 116 134 91T167 53T203 35T237 27H244L337 404Q333 404 326 403T297 395T255 379T211 350T170 304Q152 276 137 237Q122 191 122 150ZM500 282Q500 320 484 347T444 385T405 400T381 404H378L332 217L284 29Q284 27 285 27Q293 27 317 33T357 47Q400 66 431 100T475 170T494 234T500 282Z"></path></g><g data-mml-node="mo" transform="translate(4223.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(4890.7,0)"><path data-c="3A" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(5446.5,0)"><g data-mml-node="mi"><path data-c="53" d="M554 512Q536 512 536 522Q536 525 539 539T542 564Q542 588 528 604Q515 616 482 625T410 635Q374 635 349 624T312 594T295 561T290 532Q290 505 303 482T342 442T378 419T409 404Q435 391 451 383T494 357T535 323T562 282T574 231Q574 133 464 56T220 -22Q138 -22 78 21T18 123Q18 184 61 227T156 274Q178 274 178 263Q178 260 177 258Q172 247 164 239T151 227T136 218L127 213L124 202Q118 186 118 163Q120 124 165 86T292 48Q374 48 423 86T473 186V193Q473 267 347 327Q268 364 239 389Q191 431 191 486Q191 547 242 600T356 679T470 705Q472 705 478 705T489 704Q551 704 596 682T642 610Q642 566 621 545Q592 516 554 512Z"></path></g></g><g data-mml-node="mo" transform="translate(6310.7,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(7310.9,0)"><g data-mml-node="mi"><path data-c="44" d="M37 475Q19 475 19 487Q19 536 103 604T327 682H356Q386 683 408 683H419Q475 683 506 681T582 668T667 633Q766 571 766 450Q766 365 723 287T611 152T455 57T279 6Q248 1 160 0Q148 0 131 0T108 -1Q72 -1 72 11Q72 24 90 40T133 64L144 68L152 88Q247 328 272 587Q275 613 272 613Q272 613 269 613Q225 610 195 602T149 579T129 556T119 532Q118 530 116 525T113 518Q102 502 80 490T37 475ZM665 407Q665 596 412 613Q403 614 383 614Q370 614 370 612Q370 598 363 542T323 357T242 103L228 69H265Q391 73 481 119Q536 148 575 188T633 268T658 338T665 392V407Z"></path></g></g><g data-mml-node="mo" transform="translate(8359.7,0)"><path data-c="2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(9637.5,0)"><g data-mml-node="mi"><path data-c="211D" d="M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z"></path></g></g><g data-mml-node="mo" transform="translate(10359.5,0)"><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g></g></g></svg></mjx-container>（即一个预测模型支持多个数据集）</p><p>接下来需要训练这个模型，通过每次迭代采样任务<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.029ex;" xmlns="http://www.w3.org/2000/svg" width="1.17ex" height="1.005ex" role="img" focusable="false" viewBox="0 -431 517 444"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z"></path></g></g></g></svg></mjx-container>，对任务分布<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="4.068ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 1798 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mo" transform="translate(503,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(892,0)"><path data-c="1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z"></path></g><g data-mml-node="mo" transform="translate(1409,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>进行泛化，如下：</p><p><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -2.769ex;" xmlns="http://www.w3.org/2000/svg" width="27.603ex" height="4.466ex" role="img" focusable="false" viewBox="0 -750 12200.6 1974.1"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="munder"><g data-mml-node="mo"><path data-c="6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path data-c="69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z" transform="translate(833,0)"></path><path data-c="6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z" transform="translate(1111,0)"></path></g><g data-mml-node="TeXAtom" transform="translate(622.8,-657.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D719" d="M409 688Q413 694 421 694H429H442Q448 688 448 686Q448 679 418 563Q411 535 404 504T392 458L388 442Q388 441 397 441T429 435T477 418Q521 397 550 357T579 260T548 151T471 65T374 11T279 -10H275L251 -105Q245 -128 238 -160Q230 -192 227 -198T215 -205H209Q189 -205 189 -198Q189 -193 211 -103L234 -11Q234 -10 226 -10Q221 -10 206 -8T161 6T107 36T62 89T43 171Q43 231 76 284T157 370T254 422T342 441Q347 441 348 445L378 567Q409 686 409 688ZM122 150Q122 116 134 91T167 53T203 35T237 27H244L337 404Q333 404 326 403T297 395T255 379T211 350T170 304Q152 276 137 237Q122 191 122 150ZM500 282Q500 320 484 347T444 385T405 400T381 404H378L332 217L284 29Q284 27 285 27Q293 27 317 33T357 47Q400 66 431 100T475 170T494 234T500 282Z"></path></g></g></g><g data-mml-node="munder" transform="translate(1833.7,0)"><g data-mml-node="mo" transform="translate(565.5,0)"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="TeXAtom" transform="translate(0,-947.3) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z"></path></g><g data-mml-node="mo" transform="translate(517,0)"><path data-c="223C" d="M55 166Q55 241 101 304T222 367Q260 367 296 349T362 304T421 252T484 208T554 189Q616 189 655 236T694 338Q694 350 698 358T708 367Q722 367 722 334Q722 260 677 197T562 134H554Q517 134 481 152T414 196T355 248T292 293T223 311Q179 311 145 286Q109 257 96 218T80 156T69 133Q55 133 55 166Z"></path></g><g data-mml-node="mi" transform="translate(1295,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mo" transform="translate(1798,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(2187,0)"><path data-c="1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z"></path></g><g data-mml-node="mo" transform="translate(2704,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(4187.4,0)"><g data-mml-node="mi"><path data-c="4C" d="M62 -22T47 -22T32 -11Q32 -1 56 24T83 55Q113 96 138 172T180 320T234 473T323 609Q364 649 419 677T531 705Q559 705 578 696T604 671T615 645T618 623V611Q618 582 615 571T598 548Q581 531 558 520T518 509Q503 509 503 520Q503 523 505 536T507 560Q507 590 494 610T452 630Q423 630 410 617Q367 578 333 492T271 301T233 170Q211 123 204 112L198 103L224 102Q281 102 369 79T509 52H523Q535 64 544 87T579 128Q616 152 641 152Q656 152 656 142Q656 101 588 40T433 -22Q381 -22 289 1T156 28L141 29L131 20Q111 0 87 -11Z"></path></g></g><g data-mml-node="mo" transform="translate(4877.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(5266.4,0)"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mo" transform="translate(5816.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(6205.4,0)"><g data-mml-node="mi"><path data-c="1D412" d="M64 493Q64 582 120 636T264 696H272Q280 697 285 697Q380 697 454 645L480 669Q484 672 488 676T495 683T500 688T504 691T508 693T511 695T514 696T517 697T522 697Q536 697 539 691T542 652V577Q542 557 542 532T543 500Q543 472 540 465T524 458H511H505Q489 458 485 461T479 478Q472 529 449 564T393 614T336 634T287 639Q228 639 203 610T177 544Q177 517 195 493T247 457Q253 454 343 436T475 391Q574 326 574 207V200Q574 163 559 120Q517 12 389 -9Q380 -10 346 -10Q308 -10 275 -5T221 7T184 22T160 35T151 40L126 17Q122 14 118 10T111 3T106 -2T102 -5T98 -7T95 -9T92 -10T89 -11T84 -11Q70 -11 67 -4T64 35V108Q64 128 64 153T63 185Q63 203 63 211T69 223T77 227T94 228H100Q118 228 122 225T126 205Q130 125 193 88T345 51Q408 51 434 82T460 157Q460 196 439 221T388 257Q384 259 305 276T221 295Q155 313 110 366T64 493Z"></path></g></g><g data-mml-node="mo" transform="translate(6844.4,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msup" transform="translate(7289.1,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D403" d="M39 624V686H270H310H408Q500 686 545 680T638 649Q768 584 805 438Q817 388 817 338Q817 171 702 75Q628 17 515 2Q504 1 270 0H39V62H147V624H39ZM655 337Q655 370 655 390T650 442T639 494T616 540T580 580T526 607T451 623Q443 624 368 624H298V62H377H387H407Q445 62 472 65T540 83T606 129Q629 156 640 195T653 262T655 337Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(915,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z"></path></g></g></g><g data-mml-node="mo" transform="translate(8619.7,0)"><path data-c="3B" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 85 94 103T137 121Q202 121 202 8Q202 -44 183 -94T144 -169T118 -194Q115 -194 106 -186T95 -174Q94 -171 107 -155T137 -107T160 -38Q161 -32 162 -22T165 -4T165 4Q165 5 161 4T142 0Q110 0 94 18T78 60Z"></path></g><g data-mml-node="mi" transform="translate(9064.3,0)"><path data-c="1D719" d="M409 688Q413 694 421 694H429H442Q448 688 448 686Q448 679 418 563Q411 535 404 504T392 458L388 442Q388 441 397 441T429 435T477 418Q521 397 550 357T579 260T548 151T471 65T374 11T279 -10H275L251 -105Q245 -128 238 -160Q230 -192 227 -198T215 -205H209Q189 -205 189 -198Q189 -193 211 -103L234 -11Q234 -10 226 -10Q221 -10 206 -8T161 6T107 36T62 89T43 171Q43 231 76 284T157 370T254 422T342 441Q347 441 348 445L378 567Q409 686 409 688ZM122 150Q122 116 134 91T167 53T203 35T237 27H244L337 404Q333 404 326 403T297 395T255 379T211 350T170 304Q152 276 137 237Q122 191 122 150ZM500 282Q500 320 484 347T444 385T405 400T381 404H378L332 217L284 29Q284 27 285 27Q293 27 317 33T357 47Q400 66 431 100T475 170T494 234T500 282Z"></path></g><g data-mml-node="mo" transform="translate(9660.3,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(10049.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msup" transform="translate(10494,0)"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D418" d="M605 0Q581 3 434 3Q286 3 262 0H250V62H358V275L126 624H19V686H30Q54 683 189 683Q361 685 370 686H383V624H308L319 608Q330 591 353 556T396 491L484 359L660 623Q660 624 623 624H585V686H595Q613 683 728 683Q832 683 841 686H849V624H742L509 274V62H618V0H605Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(902,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D70F" d="M39 284Q18 284 18 294Q18 301 45 338T99 398Q134 425 164 429Q170 431 332 431Q492 431 497 429Q517 424 517 402Q517 388 508 376T485 360Q479 358 389 358T299 356Q298 355 283 274T251 109T233 20Q228 5 215 -4T186 -13Q153 -13 153 20V30L203 192Q214 228 227 272T248 336L254 357Q254 358 208 358Q206 358 197 358T183 359Q105 359 61 295Q56 287 53 286T39 284Z"></path></g></g></g><g data-mml-node="mo" transform="translate(11811.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></p><p>但是没有考虑到教师：</p><ul><li>对于相同的数据集，如果教师不同，最优的学生架构也会不同。然而，现有的元预测模型没有对教师进行编码，因此将为不同的教师搜索相同的学生架构，这可能是次优的。因此，我们需要为DaNAS建立一个以教师为条件的准确性预测模型。</li><li>没有使用基于（教师的准确性）梯度的适应。</li></ul><p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/ShuaiLv-JNU/blogImage/main/img/202305311918400.png"></p><h3 id="2-4-method"><a href="#2-4-method" class="headerlink" title="2.4 method"></a>2.4 method</h3><p>——</p>]]></content:encoded>
      
      
      <category domain="http://blogls.top/categories/PaperReading/">PaperReading</category>
      
      
      <category domain="http://blogls.top/tags/meta-learning/">meta learning</category>
      
      <category domain="http://blogls.top/tags/NAS/">NAS</category>
      
      
      <comments>http://blogls.top/2023/05/31/2023-ICLR-Meta-prediction-Model-for-Distillation-Aware-NAS-on-Unseen-Datasets/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>2023-ICLR-Transfer NAS with Meta-learned Bayesian Surrogates</title>
      <link>http://blogls.top/2023/05/30/2023-ICLR-Transfer-NAS-with-Meta-learned-Bayesian-Surrogates/</link>
      <guid>http://blogls.top/2023/05/30/2023-ICLR-Transfer-NAS-with-Meta-learned-Bayesian-Surrogates/</guid>
      <pubDate>Tue, 30 May 2023 14:47:33 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;1-论文&quot;&gt;&lt;a href=&quot;#1-论文&quot; class=&quot;headerlink&quot; title=&quot;1.论文&quot;&gt;&lt;/a&gt;1.论文&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;这篇论文提出了一种新的神经网络结构搜索方法，称为“Transfer NAS with Meta-Learned </description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="1-论文"><a href="#1-论文" class="headerlink" title="1.论文"></a>1.论文</h2><ul><li>这篇论文提出了一种新的神经网络结构搜索方法，称为“Transfer NAS with Meta-Learned Bayesian Surrogates”。该方法使用贝叶斯优化（BO）和深度内核高斯过程（DKGP）来进行神经网络结构搜索。此外，该方法还使用图神经网络（GNN）和基于Transformer的数据集编码器来获得架构嵌入和数据集上下文特征。该方法在六个计算机视觉数据集上实现了最先进的结果，并且与黑盒优化方法相比，具有与一次性NAS方法相同数量级的计算成本。此外，该方法还可以在不同数据集之间传递信息，从而提高了效率。</li><li>相对于以前的方法，该方法具有以下优点：<ul><li>该方法可以在不同数据集之间传递信息，从而提高了效率；</li><li>该方法可以利用以前的深度学习经验，从而更快地找到最佳架构；</li><li>该方法可以在不同数据集上进行元学习，从而更好地适应新任务。</li></ul></li><li>该方法的主要步骤如下：<ul><li>首先，使用GNN将神经网络结构嵌入到向量空间中；</li><li>然后，使用Transformer编码器将数据集上下文特征编码为向量；</li><li>接下来，使用DKGP学习嵌入空间中架构和数据集之间的内核；</li><li>最后，在嵌入空间中使用BO进行优化。</li></ul></li></ul><p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/ShuaiLv-JNU/blogImage/main/img/202305302252677.png"></p><ul><li>在实验部分，作者将其方法与其他NAS方法进行了比较，并在六个计算机视觉数据集上实现了最先进的结果。例如，在CIFAR-10数据集上，作者的方法达到了3.5%的测试误差率，并且速度比其他NAS方法快得多。</li><li>作者指出，该方法仍存在一些问题。例如，在大型数据集上进行元学习仍然是一个挑战。此外，在某些情况下，该方法可能会受到过拟合的影响。</li></ul><h2 id="2-代码"><a href="#2-代码" class="headerlink" title="2.代码"></a>2.代码</h2><h3 id="2-1main"><a href="#2-1main" class="headerlink" title="2.1main"></a>2.1main</h3><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###########################################################################################</span></span><br><span class="line"><span class="comment"># Copyright (c) Hayeon Lee, Eunyoung Hyung [GitHub MetaD2A], 2021</span></span><br><span class="line"><span class="comment"># Rapid Neural Architecture Search by Learning to Generate Graphs from Datasets, ICLR 2021</span></span><br><span class="line"><span class="comment">###########################################################################################</span></span><br><span class="line"><span class="comment">## Step1:导入相关库函数</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.optim.lr_scheduler <span class="keyword">import</span> ReduceLROnPlateau</span><br><span class="line"></span><br><span class="line"><span class="comment"># from parser import get_parser</span></span><br><span class="line"><span class="keyword">from</span> generator <span class="keyword">import</span> Generator</span><br><span class="line"><span class="keyword">from</span> predictor <span class="keyword">import</span> Predictor</span><br><span class="line">sys.path.append(os.getcwd())</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">str2bool</span>(<span class="params">v</span>):</span><br><span class="line">  <span class="keyword">return</span> v.lower() <span class="keyword">in</span> [<span class="string">'t'</span>, <span class="string">'true'</span>, <span class="literal">True</span>]<span class="comment"># 判断是否为True</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Step2:设置输入参数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_parser</span>():</span><br><span class="line">  parser = argparse.ArgumentParser()</span><br><span class="line">  <span class="comment"># general settings</span></span><br><span class="line">  parser.add_argument(<span class="string">'--seed'</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">333</span>)</span><br><span class="line">  parser.add_argument(<span class="string">'--gpu'</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">'0'</span>, <span class="built_in">help</span>=<span class="string">'set visible gpus'</span>)</span><br><span class="line">  parser.add_argument(<span class="string">'--model_name'</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">'generator'</span>, <span class="built_in">help</span>=<span class="string">'select model [generator|predictor]'</span>)</span><br><span class="line">  parser.add_argument(<span class="string">'--save-path'</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">'C:\\Users\\gress\\OneDrive\\Documents\\Gresa\\DeepKernelGP\\MetaD2A_nas_bench_201\\results'</span>, <span class="built_in">help</span>=<span class="string">'the path of save directory'</span>)</span><br><span class="line">  parser.add_argument(<span class="string">'--data-path'</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">'C:\\Users\\gress\\OneDrive\\Documents\\Gresa\\DeepKernelGP\\MetaD2A_nas_bench_201\\data'</span>, <span class="built_in">help</span>=<span class="string">'the path of save directory'</span>)</span><br><span class="line">  parser.add_argument(<span class="string">'--save-epoch'</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">400</span>,</span><br><span class="line">                      <span class="built_in">help</span>=<span class="string">'how many epochs to wait each time to save model states'</span>)</span><br><span class="line">  parser.add_argument(<span class="string">'--max-epoch'</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">400</span>, <span class="built_in">help</span>=<span class="string">'number of epochs to train'</span>)</span><br><span class="line">  parser.add_argument(<span class="string">'--batch_size'</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">1</span>, <span class="built_in">help</span>=<span class="string">'batch size for generator'</span>)</span><br><span class="line">  parser.add_argument(<span class="string">'--graph-data-name'</span>, default=<span class="string">'nasbench201'</span>, <span class="built_in">help</span>=<span class="string">'graph dataset name'</span>)</span><br><span class="line">  parser.add_argument(<span class="string">'--nvt'</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">7</span>,</span><br><span class="line">                      <span class="built_in">help</span>=<span class="string">'number of different node types, 7: NAS-Bench-201 including in/out node'</span>)</span><br><span class="line">  <span class="comment"># set encoder</span></span><br><span class="line">  parser.add_argument(<span class="string">'--num-sample'</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">20</span>, <span class="built_in">help</span>=<span class="string">'the number of images as input for set encoder'</span>)</span><br><span class="line">  <span class="comment"># graph encoder</span></span><br><span class="line">  parser.add_argument(<span class="string">'--hs'</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">56</span>, <span class="built_in">help</span>=<span class="string">'hidden size of GRUs'</span>)</span><br><span class="line">  parser.add_argument(<span class="string">'--nz'</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">56</span>, <span class="built_in">help</span>=<span class="string">'the number of dimensions of latent vectors z'</span>)</span><br><span class="line">  <span class="comment"># test</span></span><br><span class="line">  parser.add_argument(<span class="string">'--test'</span>, action=<span class="string">'store_true'</span>, default=<span class="literal">True</span>, <span class="built_in">help</span>=<span class="string">'turn on test mode'</span>)</span><br><span class="line">  parser.add_argument(<span class="string">'--load-epoch'</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">400</span>, <span class="built_in">help</span>=<span class="string">'checkpoint epoch loaded for meta-test'</span>)</span><br><span class="line">  parser.add_argument(<span class="string">'--data-name'</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="literal">None</span>, <span class="built_in">help</span>=<span class="string">'meta-test dataset name'</span>)</span><br><span class="line">  parser.add_argument(<span class="string">'--num-class'</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="literal">None</span>, <span class="built_in">help</span>=<span class="string">'the number of class of dataset'</span>)</span><br><span class="line">  parser.add_argument(<span class="string">'--num-gen-arch'</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">800</span>,</span><br><span class="line">                      <span class="built_in">help</span>=<span class="string">'the number of candidate architectures generated by the generator'</span>)</span><br><span class="line">  parser.add_argument(<span class="string">'--train-arch'</span>, <span class="built_in">type</span>=str2bool, default=<span class="literal">True</span>, <span class="built_in">help</span>=<span class="string">'whether to train the searched architecture'</span>)</span><br><span class="line"></span><br><span class="line">  args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> args</span><br><span class="line"></span><br><span class="line"><span class="comment">## Step3:主函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">  args = get_parser()<span class="comment"># 获取命令行参数</span></span><br><span class="line">  os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>]=args.gpu<span class="comment"># 指定可见的CUDA设备</span></span><br><span class="line">  device = torch.device(<span class="string">"cuda:0"</span>)</span><br><span class="line">  torch.cuda.manual_seed(args.seed)<span class="comment"># 设置CUDA种子</span></span><br><span class="line">  torch.manual_seed(args.seed)<span class="comment"># 设置CPU种子</span></span><br><span class="line">  np.random.seed(args.seed)</span><br><span class="line">  random.seed(args.seed)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(args.save_path):</span><br><span class="line">    os.makedirs(args.save_path)</span><br><span class="line">  args.model_path = os.path.join(args.save_path, args.model_name, <span class="string">'model'</span>)</span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(args.model_path):</span><br><span class="line">    os.makedirs(args.model_path)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> args.model_name == <span class="string">'generator'</span>:</span><br><span class="line">    g = Generator(args)</span><br><span class="line">    <span class="keyword">if</span> args.test:</span><br><span class="line">      g.meta_test()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      g.meta_train()</span><br><span class="line">  <span class="keyword">elif</span> args.model_name == <span class="string">'predictor'</span>:</span><br><span class="line">    p = Predictor(args)</span><br><span class="line">    <span class="keyword">if</span> args.test:</span><br><span class="line">      p.meta_test()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      p.meta_train()</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(<span class="string">'You should select generator|predictor|train_arch'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">  main()</span><br><span class="line"></span><br></pre></td></tr></table></figure></div><h3 id="2-2process-dataset"><a href="#2-2process-dataset" class="headerlink" title="2.2process_dataset"></a>2.2process_dataset</h3><div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"><span class="keyword">import</span> torchvision.datasets <span class="keyword">as</span> dset</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> os, sys</span><br><span class="line"><span class="keyword">if</span> sys.version_info[<span class="number">0</span>] == <span class="number">2</span>:</span><br><span class="line"><span class="keyword">import</span> cPickle <span class="keyword">as</span> pickle</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser(<span class="string">"sota"</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--gpu'</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">'0'</span>, <span class="built_in">help</span>=<span class="string">'set visible gpus'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--data-path'</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">'data'</span>, <span class="built_in">help</span>=<span class="string">'the path of save directory'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--dataset'</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">'cifar10'</span>, <span class="built_in">help</span>=<span class="string">'choose dataset'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'--seed'</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=-<span class="number">1</span>, <span class="built_in">help</span>=<span class="string">'random seed'</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> args.seed <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> args.seed &lt; <span class="number">0</span>: args.seed = random.randint(<span class="number">1</span>, <span class="number">100000</span>)</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = args.gpu</span><br><span class="line">np.random.seed(args.seed)</span><br><span class="line">random.seed(args.seed)</span><br><span class="line"></span><br><span class="line"><span class="comment"># remove last fully-connected layer</span></span><br><span class="line">model = models.resnet18(pretrained=<span class="literal">True</span>).<span class="built_in">eval</span>()</span><br><span class="line">feature_extractor = torch.nn.Sequential(*<span class="built_in">list</span>(model.children())[:-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_transform</span>(<span class="params">dataset</span>):</span><br><span class="line"><span class="keyword">if</span> args.dataset == <span class="string">'mnist'</span>:</span><br><span class="line">mean, std = [<span class="number">0.1307</span>, <span class="number">0.1307</span>, <span class="number">0.1307</span>], [<span class="number">0.3081</span>, <span class="number">0.3081</span>, <span class="number">0.3081</span>]</span><br><span class="line"><span class="keyword">elif</span> args.dataset == <span class="string">'svhn'</span>:</span><br><span class="line">mean, std = [<span class="number">0.4376821</span>, <span class="number">0.4437697</span>, <span class="number">0.47280442</span>], [<span class="number">0.19803012</span>, <span class="number">0.20101562</span>, <span class="number">0.19703614</span>]</span><br><span class="line"><span class="keyword">elif</span> args.dataset == <span class="string">'cifar10'</span>:</span><br><span class="line">mean = [x / <span class="number">255</span> <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="number">125.3</span>, <span class="number">123.0</span>, <span class="number">113.9</span>]]</span><br><span class="line">std = [x / <span class="number">255</span> <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="number">63.0</span>, <span class="number">62.1</span>, <span class="number">66.7</span>]]</span><br><span class="line"><span class="keyword">elif</span> args.dataset == <span class="string">'cifar100'</span>:</span><br><span class="line">mean = [x / <span class="number">255</span> <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="number">129.3</span>, <span class="number">124.1</span>, <span class="number">112.4</span>]]</span><br><span class="line">std = [x / <span class="number">255</span> <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="number">68.2</span>, <span class="number">65.4</span>, <span class="number">70.4</span>]]</span><br><span class="line"><span class="keyword">elif</span> args.dataset == <span class="string">'imagenet32'</span>:</span><br><span class="line">mean = [x / <span class="number">255</span> <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="number">122.68</span>, <span class="number">116.66</span>, <span class="number">104.01</span>]]</span><br><span class="line">std = [x / <span class="number">255</span> <span class="keyword">for</span> x <span class="keyword">in</span> [<span class="number">66.22</span>, <span class="number">64.20</span>, <span class="number">67.86</span>]]</span><br><span class="line"></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">transforms.Resize((<span class="number">32</span>, <span class="number">32</span>)),</span><br><span class="line">transforms.ToTensor(),</span><br><span class="line">transforms.Normalize(mean, std),</span><br><span class="line">])</span><br><span class="line"><span class="keyword">if</span> dataset == <span class="string">'mnist'</span>:</span><br><span class="line">transform.transforms.append(transforms.Lambda(<span class="keyword">lambda</span> x: x.repeat(<span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)))</span><br><span class="line"><span class="keyword">return</span> transform</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">process</span>(<span class="params">dataset, n_classes</span>):</span><br><span class="line">data_label = {i: [] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_classes)}</span><br><span class="line"><span class="keyword">for</span> x, y <span class="keyword">in</span> dataset:</span><br><span class="line">data_label[y].append(x)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_classes):</span><br><span class="line">data_label[i] = torch.stack(data_label[i])</span><br><span class="line"></span><br><span class="line">holder = {i: [] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_classes)}</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_classes):</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">data = feature_extractor(data_label[i])</span><br><span class="line">holder[i].append(data.squeeze())</span><br><span class="line"><span class="keyword">return</span> holder</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ImageNet32</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">train_list = [</span><br><span class="line">[<span class="string">'train_data_batch_1'</span>, <span class="string">'27846dcaa50de8e21a7d1a35f30f0e91'</span>],</span><br><span class="line">[<span class="string">'train_data_batch_2'</span>, <span class="string">'c7254a054e0e795c69120a5727050e3f'</span>],</span><br><span class="line">[<span class="string">'train_data_batch_3'</span>, <span class="string">'4333d3df2e5ffb114b05d2ffc19b1e87'</span>],</span><br><span class="line">[<span class="string">'train_data_batch_4'</span>, <span class="string">'1620cdf193304f4a92677b695d70d10f'</span>],</span><br><span class="line">[<span class="string">'train_data_batch_5'</span>, <span class="string">'348b3c2fdbb3940c4e9e834affd3b18d'</span>],</span><br><span class="line">[<span class="string">'train_data_batch_6'</span>, <span class="string">'6e765307c242a1b3d7d5ef9139b48945'</span>],</span><br><span class="line">[<span class="string">'train_data_batch_7'</span>, <span class="string">'564926d8cbf8fc4818ba23d2faac7564'</span>],</span><br><span class="line">[<span class="string">'train_data_batch_8'</span>, <span class="string">'f4755871f718ccb653440b9dd0ebac66'</span>],</span><br><span class="line">[<span class="string">'train_data_batch_9'</span>, <span class="string">'bb6dd660c38c58552125b1a92f86b5d4'</span>],</span><br><span class="line">[<span class="string">'train_data_batch_10'</span>, <span class="string">'8f03f34ac4b42271a294f91bf480f29b'</span>],</span><br><span class="line">]</span><br><span class="line">valid_list = [</span><br><span class="line">[<span class="string">'val_data'</span>, <span class="string">'3410e3017fdaefba8d5073aaa65e4bd6'</span>],</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, root, n_class, transform</span>):</span><br><span class="line">self.transform = transform</span><br><span class="line">downloaded_list = self.train_list</span><br><span class="line">self.n_class = n_class</span><br><span class="line">self.data_label = {i: [] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_class)}</span><br><span class="line">self.data = []</span><br><span class="line">self.targets = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, (file_name, checksum) <span class="keyword">in</span> <span class="built_in">enumerate</span>(downloaded_list):</span><br><span class="line">file_path = os.path.join(root, file_name)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line"><span class="keyword">if</span> sys.version_info[<span class="number">0</span>] == <span class="number">2</span>:</span><br><span class="line">entry = pickle.load(f)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">entry = pickle.load(f, encoding=<span class="string">'latin1'</span>)</span><br><span class="line"><span class="keyword">for</span> j, k <span class="keyword">in</span> <span class="built_in">enumerate</span>(entry[<span class="string">'labels'</span>]):</span><br><span class="line">self.data_label[k - <span class="number">1</span>].append(entry[<span class="string">'data'</span>][j])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_class):</span><br><span class="line">self.data_label[i] = np.vstack(self.data_label[i]).reshape(-<span class="number">1</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">self.data_label[i] = self.data_label[i].transpose((<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>))  <span class="comment"># convert to HWC</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get</span>(<span class="params">self, use_num_cls, max_num=<span class="literal">None</span></span>):</span><br><span class="line"><span class="keyword">assert</span> <span class="built_in">isinstance</span>(use_num_cls, <span class="built_in">list</span>) \</span><br><span class="line">       <span class="keyword">and</span> <span class="built_in">len</span>(use_num_cls) &gt; <span class="number">0</span> <span class="keyword">and</span> <span class="built_in">len</span>(use_num_cls) &lt; self.n_class, \</span><br><span class="line"><span class="string">'invalid use_num_cls : {:}'</span>.<span class="built_in">format</span>(use_num_cls)</span><br><span class="line">new_data, new_targets = [], []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> use_num_cls:</span><br><span class="line">new_data.append(self.data_label[i][:max_num] <span class="keyword">if</span> max_num <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> self.data_label[i])</span><br><span class="line">new_targets.extend([i] * max_num <span class="keyword">if</span> max_num <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line">                   <span class="keyword">else</span> [i] * <span class="built_in">len</span>(self.data_label[i]))</span><br><span class="line">self.data = np.concatenate(new_data)</span><br><span class="line">self.targets = new_targets</span><br><span class="line"></span><br><span class="line">imgs = []</span><br><span class="line"><span class="keyword">for</span> img <span class="keyword">in</span> self.data:</span><br><span class="line">img = Image.fromarray(img)</span><br><span class="line">img = self.transform(img)</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">imgs.append(feature_extractor(img.unsqueeze(<span class="number">0</span>)).squeeze().unsqueeze(<span class="number">0</span>))</span><br><span class="line"><span class="keyword">return</span> torch.cat(imgs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">ncls = {<span class="string">'mnist'</span>: <span class="number">10</span>, <span class="string">'svhn'</span>: <span class="number">10</span>, <span class="string">'cifar10'</span>: <span class="number">10</span>, <span class="string">'cifar100'</span>: <span class="number">100</span>, <span class="string">'imagenet32'</span>: <span class="number">1000</span>}</span><br><span class="line">transform = get_transform(args.dataset)</span><br><span class="line"><span class="keyword">if</span> args.dataset == <span class="string">'imagenet32'</span>:</span><br><span class="line">imgnet32 = ImageNet32(args.data, ncls[args.dataset], transform)</span><br><span class="line">data_label = {i: [] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>)}</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">m = imgnet32.get([i])</span><br><span class="line">data_label[i].append(m)</span><br><span class="line"><span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f'Currently saving features of <span class="subst">{i}</span>-th class'</span>)</span><br><span class="line">torch.save(data_label, <span class="string">f'<span class="subst">{args.save_path}</span>/<span class="subst">{args.dataset}</span>bylabel.pt'</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="keyword">if</span> args.dataset == <span class="string">'mnist'</span>:</span><br><span class="line">data = dset.MNIST(args.data_path, train=<span class="literal">True</span>, transform=transform, download=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">elif</span> args.dataset == <span class="string">'svhn'</span>:</span><br><span class="line">data = dset.SVHN(args.data_path, split=<span class="string">'train'</span>, transform=transform, download=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">elif</span> args.dataset == <span class="string">'cifar10'</span>:</span><br><span class="line">data = dset.CIFAR10(args.data_path, train=<span class="literal">True</span>, transform=transform, download=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">elif</span> args.dataset == <span class="string">'cifar100'</span>:</span><br><span class="line">data = dset.CIFAR100(args.data_path, train=<span class="literal">True</span>, transform=transform, download=<span class="literal">True</span>)</span><br><span class="line">dataset = process(data, ncls[args.dataset])</span><br><span class="line">torch.save(dataset, <span class="string">f'<span class="subst">{args.save_path}</span>/<span class="subst">{args.dataset}</span>bylabel.pt'</span>)</span><br></pre></td></tr></table></figure></div>]]></content:encoded>
      
      
      
      
      <comments>http://blogls.top/2023/05/30/2023-ICLR-Transfer-NAS-with-Meta-learned-Bayesian-Surrogates/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>资源汇总</title>
      <link>http://blogls.top/2023/05/29/%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/</link>
      <guid>http://blogls.top/2023/05/29/%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/</guid>
      <pubDate>Mon, 29 May 2023 15:21:41 GMT</pubDate>
      
        
        
      <description>&lt;ul&gt;
&lt;li&gt;&lt;h2 id=&quot;工具-科研辅助AI软件——inciteful-哔哩哔哩-bilibili-Zotero-GPT-与ChatGPT一起读文献-哔哩哔哩-bilibili-Zotero-利用Research-Rabbit了解研究领域的相关文献，获取同一作者已发表的所</description>
        
      
      
      
      <content:encoded><![CDATA[<ul><li><h2 id="工具-科研辅助AI软件——inciteful-哔哩哔哩-bilibili-Zotero-GPT-与ChatGPT一起读文献-哔哩哔哩-bilibili-Zotero-利用Research-Rabbit了解研究领域的相关文献，获取同一作者已发表的所有文献-哔哩哔哩-bilibili"><a href="#工具-科研辅助AI软件——inciteful-哔哩哔哩-bilibili-Zotero-GPT-与ChatGPT一起读文献-哔哩哔哩-bilibili-Zotero-利用Research-Rabbit了解研究领域的相关文献，获取同一作者已发表的所有文献-哔哩哔哩-bilibili" class="headerlink" title="工具- 科研辅助AI软件——inciteful_哔哩哔哩_bilibili- Zotero GPT | 与ChatGPT一起读文献_哔哩哔哩_bilibili- Zotero|利用Research Rabbit了解研究领域的相关文献，获取同一作者已发表的所有文献_哔哩哔哩_bilibili"></a><strong>工具</strong><br>- <a class="link" href="https://www.bilibili.com/video/BV1UM4y1b7w8/?spm_id_from=333.1007.tianma.7-2-24.click&vd_source=5bc699d65b90929607821ea2dff49140">科研辅助AI软件——inciteful_哔哩哔哩_bilibili <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a><br>- <a class="link" href="https://www.bilibili.com/video/BV1Wa4y1V777/?spm_id_from=333.999.0.0&vd_source=5bc699d65b90929607821ea2dff49140">Zotero GPT | 与ChatGPT一起读文献_哔哩哔哩_bilibili <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a><br>- <a class="link" href="https://www.bilibili.com/video/BV1rh4y1474B/?spm_id_from=333.1007.tianma.6-4-22.click&vd_source=5bc699d65b90929607821ea2dff49140">Zotero|利用Research Rabbit了解研究领域的相关文献，获取同一作者已发表的所有文献_哔哩哔哩_bilibili <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></h2></li><li><p>hexo</p><ul><li><a class="link" href="https://blog.csdn.net/Awt_FuDongLai/article/details/107424098">(213条消息) hexo笔记四：next主题添加作者头像_hexo设置自己的头像_小镇攻城狮的博客-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li><li><a class="link" href="https://blog.csdn.net/qq_38140292/article/details/119076424#:~:text=%E3%80%90hexo%E3%80%91%E5%9F%BA%E7%A1%80,%E5%AE%A2-CSDN%E5%8D%9A%E5%AE%A2">(212条消息) 【hexo】基础教程-三-添加网易云音乐_指尖听戏的博客-CSDN博客 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li><li><a class="link" href="https://cloud.tencent.com/developer/article/1662733">Hexo博客教程（二）| 如何写作新文章并发布-腾讯云开发者社区-腾讯云 (tencent.com) <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li><li><a class="link" href="https://zhuanlan.zhihu.com/p/350654582">Hexo-如何养一只看板娘(博客宠物) - 知乎 (zhihu.com) <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li><li><strong><a class="link" href="https://redefine-docs.ohevan.com/basic/global">全局功能设置 global - Redefine Docs (ohevan.com) <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></strong></li></ul></li><li><p>论文</p><ul><li><a class="link" href="https://www.bilibili.com/video/BV1DL41167ox/?p=2&spm_id_from=pageDriver&vd_source=5bc699d65b90929607821ea2dff49140">Transformer在医学分割领域应用与拓展_哔哩哔哩_bilibili <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li><li><a class="link" href="https://github.com/Somedaywilldo/BM-NAS/blob/master/structure_vis.ipynb">BM-NAS/structure_vis.ipynb at master · Somedaywilldo/BM-NAS · GitHub — BM-NAS/structure_vis.ipynb at master ·总有一天会/BM-NAS ·GitHub <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li><li>[<a class="link" href="https://www.youtube.com/watch?v=EGZu5bOi_M4">AAAI 2022 Oral] BM-NAS: Bilevel Multimodal Neural Architecture Search [Full] - YouTube <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li><li><a class="link" href="https://arxiv.org/pdf/2008.10937.pdf">2008.10937.pdf (arxiv.org) <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li><li><a class="link" href="https://github.com/Shengcao-Cao/ESNAC">Shengcao-Cao/ESNAC: Learnable Embedding Space for Efficient Neural Architecture Compression (github.com) <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li><li><a class="link" href="https://www.sciencedirect.com/science/article/pii/S0957417422012581">用于自动多模态学习的神经架构搜索 - ScienceDirect <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li></ul></li><li><p>原理</p><ul><li><a class="link" href="https://www.bilibili.com/video/BV1ih4y1J7rx/?spm_id_from=333.1007.tianma.6-1-19.click&vd_source=5bc699d65b90929607821ea2dff49140">超强动画，一步一步深入浅出解释Transformer原理！_哔哩哔哩_bilibili <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li><li>qiuxipeng的GitHub</li></ul></li><li><p>GitHub page</p><ul><li><a class="link" href="https://www.zhihu.com/question/20376047?sort=created">(19 封私信 / 11 条消息) 怎样做一个漂亮的 GitHub Pages 首页？ - 知乎 (zhihu.com) <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li></ul></li><li><p>视频</p><ul><li><a class="link" href="https://hub.baai.ac.cn/view/21366">不可错过！MIT韩松博士《TinyML与高效深度学习》2022课程，附Slides - 智源社区 (baai.ac.cn) <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li></ul></li><li><p>教程</p><ul><li><a class="link" href="https://github.com/labmlai">labml.ai (github.com) <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></li></ul></li></ul><p>不设置任何参数的 <a class="button " href="/" title="按钮">按钮</a> 适合融入段落中。</p><p>regular 按钮适合独立于段落之外：</p><a class="button  regular" href="https://www.ohevan.com" title="示例博客"><i class="fa-solid fa-play-circle"></i> 示例博客</a><a class="button  regular" href="https://www.ohevan.com" title="示例博客"><i class="fa-solid fa-play-circle"></i> 示例博客</a><p>large 按钮更具有强调作用，建议搭配 center 使用：</p><a class="button  center large" href="https://redefine-docs.ohevan.com" title="开始使用"><i class="fa-solid fa-download"></i> 开始使用</a><blockquote><p><a class="link" href="https://redefine-docs.ohevan.com/modules/notes">Notes 笔记模块 - Redefine Docs (ohevan.com) <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p></blockquote><p><a class="link" href="https://redefine-docs.ohevan.com/plugins/mermaid">Mermaid JS 流程图 - Redefine Docs (ohevan.com) <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p><ul><li>文章置顶：<code>sticky: 999</code>，值越大，置顶的文章越靠前</li><li>首页缩略图：<code>thumbnail: "IMAGE_LINK"</code></li><li>首页摘要：<code>excerpt: "摘要"</code></li><li>文章页头图：<code>cover: "图片链接"</code></li></ul>]]></content:encoded>
      
      
      
      
      <comments>http://blogls.top/2023/05/29/%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>ChatGPT提问模板</title>
      <link>http://blogls.top/2023/05/29/ChatGPT%E6%8F%90%E9%97%AE%E6%A8%A1%E6%9D%BF/</link>
      <guid>http://blogls.top/2023/05/29/ChatGPT%E6%8F%90%E9%97%AE%E6%A8%A1%E6%9D%BF/</guid>
      <pubDate>Mon, 29 May 2023 14:51:02 GMT</pubDate>
      
        
        
      <description>&lt;blockquote&gt;
&lt;p&gt;ref1: &lt;a class=&quot;link&quot; href=&quot;https://zhuanlan.zhihu.com/p/610735657&quot;&gt;https://zhuanlan.zhihu.com/p/610735657 &lt;i class=&quot;fa-regu</description>
        
      
      
      
      <content:encoded><![CDATA[<blockquote><p>ref1: <a class="link" href="https://zhuanlan.zhihu.com/p/610735657">https://zhuanlan.zhihu.com/p/610735657 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p></blockquote><p>Don’t search the Internet, you are now a PhD student in the field of <code>need to change according to paper</code>, and now you need to help me summarize this article according to the following contents (Please answer me in Chinese.): 1. First summarize what method, what technology is used, and what effect is achieved in this paper? 2. What are the advantages of their solution compared with the previous ones, and what problems did they solve that the previous methods could not solve? 3. Please describe the main procedure of the method in detail in combination with the content of the Method section. Please use latex to display the key variables. 4. Combined with the Experiments section, please summarize what task and performance the method achieves? Please list specific values according to this section. 5. Please combine the Conclusion section to summarize what problems still exist in this method?</p>]]></content:encoded>
      
      
      
      <category domain="http://blogls.top/tags/ChatGPT/">ChatGPT</category>
      
      
      <comments>http://blogls.top/2023/05/29/ChatGPT%E6%8F%90%E9%97%AE%E6%A8%A1%E6%9D%BF/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>2023-ICLR-Single-shot General Hyper-parameter Optimization for Federated Learning</title>
      <link>http://blogls.top/2023/05/29/2023-ICLR-Single-shot-General-Hyper-parameter-Optimization-for-Federated-Learning/</link>
      <guid>http://blogls.top/2023/05/29/2023-ICLR-Single-shot-General-Hyper-parameter-Optimization-for-Federated-Learning/</guid>
      <pubDate>Mon, 29 May 2023 14:43:21 GMT</pubDate>
      
        
        
      <description>&lt;ol&gt;
&lt;li&gt;这篇文章提出了一种名为FLoRA（Federated Loss SuRface Aggregation）的通用FL-HPO解决方案框架，它能够解决表格数据的用例，并且能够扩展到任何机器学习模型，包括梯度提升训练算法、SVM、神经网络等。FLoRA实现了单次FL-</description>
        
      
      
      
      <content:encoded><![CDATA[<ol><li>这篇文章提出了一种名为FLoRA（Federated Loss SuRface Aggregation）的通用FL-HPO解决方案框架，它能够解决表格数据的用例，并且能够扩展到任何机器学习模型，包括梯度提升训练算法、SVM、神经网络等。FLoRA实现了单次FL-HPO：确定一组好的超参数，然后在单次FL训练中使用。因此，它能够在与不进行HPO的FL训练相比，以最小的额外通信开销实现FL-HPO解决方案。在理论上，我们针对任何凸和非凸损失函数，对FLoRA的最优性差进行了表征，这显式地考虑了各方本地数据分布的异构性质，这是FL系统的一个主要特征。我们对FLoRA在七个OpenML数据集上针对多个FL算法的实证评估表明，与基线相比，模型精度显著提高，并且对参与FL-HPO训练的各方数量增加具有鲁棒性。</li></ol><h1 id="1-概览"><a href="#1-概览" class="headerlink" title="1.概览"></a>1.概览</h1><ol><li><strong>提出了什么方法，利用了什么技术，实现了什么效果？</strong>提出了一种名为FLoRA（Federated Loss SuRface Aggregation）的通用FL-HPO解决方案框架，能够解决表格数据的用例，并且能够扩展到任何机器学习模型，包括梯度提升训练算法、SVM、神经网络等。FLoRA实现了单次（single-shot）FL-HPO：确定一组好的超参数，然后在单次FL训练中使用。因此，它能够在与不进行HPO的FL训练相比，以最小的额外通信开销实现FL-HPO解决方案。在理论上，我们针对任何凸和非凸损失函数，对FLoRA的最优性差进行了表征，这显式地考虑了各方本地数据分布的异构性质，这是FL系统的一个主要特征。我们对FLoRA在七个OpenML数据集上针对多个FL算法的实证评估表明，与基线相比，模型精度显著提高，并且对参与FL-HPO训练的各方数量增加具有鲁棒性。</li><li><strong>相比过去的方案有哪些优势，解决了什么过去的方法解决不了的问题？</strong>与以前的方法相比，他们的解决方案具有以下优点：它更通用，因为它可以调整多个超参数，并且适用于非SGD训练设置，例如梯度提升树。这是通过将FL-HPO视为黑盒HPO问题实现的（与灰盒HPO相反，我们可以利用诸如权重共享和多保真度HPO之类的技术），这在集中式HPO文献中已经使用网格搜索、随机搜索和贝叶斯优化方法进行了解决。（1）关键挑战在于需要对大量的HPO配置执行计算密集型的评估，其中每次评估都涉及训练一个模型并在验证数据集上对其进行评分。在分布式FL设置中，这个问题更加严峻，因为验证集是各方本地的，而且每次FL训练/评分评估都需要大量的通信。因此，直接应用集中式黑盒HPO方法，在外循环中选择HP并继续进行FL训练评估是不可行的。（2）它产生最小的HPO通信开销。这是通过从各方本地异步HPO构建损失曲面来实现的，该损失曲面产生单个优化的HP配置，用于训练单个全局模型。 （3）它是第一个在FL-HPO设置中理论上表征最优性差距的方法，适用于我们在本文中关注的情况：通过调整多个全局HP而不访问全局验证数据集来创建全局模型。</li><li><strong>方法的main procedure：</strong>FLoRA算法主要过程如下：首先，每个参与方<mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.192ex" height="1.902ex" role="img" focusable="false" viewBox="0 -683 969 840.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mi" transform="translate(675,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>都会运行HPO以生成T（超参数、损失）对<mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="26.809ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 11849.4 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mo" transform="translate(764,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1153,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1498,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(2164.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(3220.6,0)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mo" transform="translate(858,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1247,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1592,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mi" transform="translate(1981,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(2342,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2786.7,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mo" transform="translate(3467.7,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(3856.7,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(4201.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mi" transform="translate(4590.7,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(4951.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(5340.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(5785.3,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(6424.1,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="mo" transform="translate(7368.9,0)"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mi" transform="translate(7646.9,0)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="mo" transform="translate(8350.9,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g></g></g></svg></mjx-container>，其中<mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="41.472ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 18330.8 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mo" transform="translate(469,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(858,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1203,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mi" transform="translate(1592,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(2230.8,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="mi" transform="translate(3175.6,0)"><path data-c="1D6E9" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM640 466Q640 523 625 565T583 628T532 658T479 668Q370 668 273 559T151 255Q150 245 150 213Q150 156 165 116T207 55T259 26T313 17Q385 17 451 63T561 184Q590 234 615 312T640 466ZM510 276Q510 278 512 288L515 298Q515 299 384 299H253L250 285Q246 271 244 268T231 265H227Q216 265 214 266T207 274Q207 278 223 345T244 416Q247 419 260 419H263Q280 419 280 408Q280 406 278 396L275 386Q275 385 406 385H537L540 399Q544 413 546 416T559 419H563Q574 419 576 418T583 410Q583 403 566 339Q549 271 544 267Q542 265 538 265H530H527Q510 265 510 276Z"></path></g><g data-mml-node="mo" transform="translate(3938.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(4383.2,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mo" transform="translate(5064.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(5453.2,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(5798.2,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mi" transform="translate(6187.2,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(6826,0)"><g data-mml-node="text"><path data-c="3A" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="text" transform="translate(278,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g></g><g data-mml-node="mi" transform="translate(8159.8,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mo" transform="translate(8840.8,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(9229.8,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mo" transform="translate(9979.8,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(10368.8,0)"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g><g data-mml-node="mo" transform="translate(11419.8,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(11864.4,0)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mo" transform="translate(12333.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(12722.4,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(13067.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mi" transform="translate(13456.4,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(13817.4,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(14262.1,0)"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path></g><g data-mml-node="mi" transform="translate(15090.1,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(15435.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(15824.1,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(16268.8,0)"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path></g><g data-mml-node="mn" transform="translate(17096.8,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mi" transform="translate(17596.8,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(17941.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>。<br>然后，在聚合器处收集所有<mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="15.963ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 7055.8 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mo" transform="translate(1041.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(2097.6,0)"><g data-mml-node="mi"><path data-c="1D438" d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path></g><g data-mml-node="mo" transform="translate(764,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1153,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1498,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(1887,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2331.7,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(2954.4,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="mo" transform="translate(3899.2,0)"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mi" transform="translate(4177.2,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mo" transform="translate(4680.2,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g></g></g></svg></mjx-container>。<br>接下来，使用E生成统一损失曲面<mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="9.819ex" height="1.643ex" role="img" focusable="false" viewBox="0 -704 4340.1 726"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mo" transform="translate(706.8,0)"><path data-c="3A" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path></g><g data-mml-node="mi" transform="translate(1262.6,0)"><path data-c="1D6E9" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM640 466Q640 523 625 565T583 628T532 658T479 668Q370 668 273 559T151 255Q150 245 150 213Q150 156 165 116T207 55T259 26T313 17Q385 17 451 63T561 184Q590 234 615 312T640 466ZM510 276Q510 278 512 288L515 298Q515 299 384 299H253L250 285Q246 271 244 268T231 265H227Q216 265 214 266T207 274Q207 278 223 345T244 416Q247 419 260 419H263Q280 419 280 408Q280 406 278 396L275 386Q275 385 406 385H537L540 399Q544 413 546 416T559 419H563Q574 419 576 418T583 410Q583 403 566 339Q549 271 544 267Q542 265 538 265H530H527Q510 265 510 276Z"></path></g><g data-mml-node="mo" transform="translate(2303.3,0)"><path data-c="2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(3581.1,0)"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g></g></g></svg></mjx-container>。<br>然后选择最佳超参数候选<mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="23.385ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 10336.1 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mi" transform="translate(469,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mo" transform="translate(898,0)"><path data-c="3F" d="M226 668Q190 668 162 656T124 632L114 621Q116 621 119 620T130 616T145 607T157 591T162 567Q162 544 147 529T109 514T71 528T55 566Q55 625 100 661T199 704Q201 704 210 704T224 705H228Q281 705 320 692T378 656T407 612T416 567Q416 503 361 462Q267 395 247 303Q242 279 242 241V224Q242 205 239 202T222 198T205 201T202 218V249Q204 320 220 371T255 445T292 491T315 537Q317 546 317 574V587Q317 604 315 615T304 640T277 661T226 668ZM162 61Q162 89 180 105T224 121Q247 119 264 104T281 61Q281 31 264 16T222 1Q197 1 180 16T162 61Z"></path></g><g data-mml-node="mo" transform="translate(1647.8,0)"><path data-c="2190" d="M944 261T944 250T929 230H165Q167 228 182 216T211 189T244 152T277 96T303 25Q308 7 308 0Q308 -11 288 -11Q281 -11 278 -11T272 -7T267 2T263 21Q245 94 195 151T73 236Q58 242 55 247Q55 254 59 257T73 264Q121 283 158 314T215 375T247 434T264 480L267 497Q269 503 270 505T275 509T288 511Q308 511 308 500Q308 493 303 475Q293 438 278 406T246 352T215 315T185 287T165 270H929Q944 261 944 250Z"></path></g><g data-mml-node="mi" transform="translate(2925.6,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(3454.6,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3905.6,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(4382.6,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(5260.6,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(5605.6,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6205.6,0)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mo" transform="translate(6952.3,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="mi" transform="translate(7897.1,0)"><path data-c="1D6E9" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM640 466Q640 523 625 565T583 628T532 658T479 668Q370 668 273 559T151 255Q150 245 150 213Q150 156 165 116T207 55T259 26T313 17Q385 17 451 63T561 184Q590 234 615 312T640 466ZM510 276Q510 278 512 288L515 298Q515 299 384 299H253L250 285Q246 271 244 268T231 265H227Q216 265 214 266T207 274Q207 278 223 345T244 416Q247 419 260 419H263Q280 419 280 408Q280 406 278 396L275 386Q275 385 406 385H537L540 399Q544 413 546 416T559 419H563Q574 419 576 418T583 410Q583 403 566 339Q549 271 544 267Q542 265 538 265H530H527Q510 265 510 276Z"></path></g><g data-mml-node="mi" transform="translate(8660.1,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mo" transform="translate(9089.1,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(9478.1,0)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mo" transform="translate(9947.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>。<br>最后，调用联合训练<mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="21.026ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 9293.6 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1155.8,0)"><path data-c="2190" d="M944 261T944 250T929 230H165Q167 228 182 216T211 189T244 152T277 96T303 25Q308 7 308 0Q308 -11 288 -11Q281 -11 278 -11T272 -7T267 2T263 21Q245 94 195 151T73 236Q58 242 55 247Q55 254 59 257T73 264Q121 283 158 314T215 375T247 434T264 480L267 497Q269 503 270 505T275 509T288 511Q308 511 308 500Q308 493 303 475Q293 438 278 406T246 352T215 315T185 287T165 270H929Q944 261 944 250Z"></path></g><g data-mml-node="mi" transform="translate(2433.6,0)"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path></g><g data-mml-node="mo" transform="translate(3182.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(3571.6,0)"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g><g data-mml-node="mo" transform="translate(4622.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(5067.2,0)"><path data-c="1D703" d="M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z"></path></g><g data-mml-node="mi" transform="translate(5536.2,0)"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mo" transform="translate(5965.2,0)"><path data-c="3F" d="M226 668Q190 668 162 656T124 632L114 621Q116 621 119 620T130 616T145 607T157 591T162 567Q162 544 147 529T109 514T71 528T55 566Q55 625 100 661T199 704Q201 704 210 704T224 705H228Q281 705 320 692T378 656T407 612T416 567Q416 503 361 462Q267 395 247 303Q242 279 242 241V224Q242 205 239 202T222 198T205 201T202 218V249Q204 320 220 371T255 445T292 491T315 537Q317 546 317 574V587Q317 604 315 615T304 640T277 661T226 668ZM162 61Q162 89 180 105T224 121Q247 119 264 104T281 61Q281 31 264 16T222 1Q197 1 180 16T162 61Z"></path></g><g data-mml-node="mo" transform="translate(6437.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(6881.9,0)"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mo" transform="translate(7631.9,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(8076.6,0)"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path></g><g data-mml-node="mo" transform="translate(8904.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>。</li><li><strong>方法在什么任务上，实现了什么性能？</strong>在实验部分，作者使用FLoRA对多种机器学习模型（HGB、SVM和MLP）在OpenML分类问题上进行了FL-HPO。与单次基线相比，所有FLoRA损失曲面都表现出强大的性能，具有明显更多的胜利而不是损失，并且第三四分位相对遗憾值小于1（表示优于基线）。所有FLoRA损失曲面的p值均小于0.05，表明我们可以拒绝零假设。总体而言，APLM在所有损失曲面中表现最佳，无论是在胜/平/负方面还是在威尔科克森符号秩检验方面，都具有最高的统计量和接近10−3的p值。APLM还具有明显低于所有其他损失曲面的第三四分位数。</li><li><strong>结论：</strong>根据结论部分，这篇文章提出了一种新颖的FL-HPO框架FLoRA，它利用元学习技术使各方能够在各自进行异步本地HPO以执行单次HPO以解决全局FL-HPO问题。作者提供了理论保证，涵盖了IID和Non-IID情况，无论损失函数的凸性如何。他们对FLoRA在OpenML上七个分类数据集上针对多个FL算法的实证评估表明，与基线相比，模型精度显著提高，并且对参与FL-HPO训练的各方数量增加具有鲁棒性。</li></ol><h1 id="2-精读"><a href="#2-精读" class="headerlink" title="2.精读"></a>2.精读</h1><p>——</p>]]></content:encoded>
      
      
      
      <category domain="http://blogls.top/tags/PaperReading/">PaperReading</category>
      
      
      <comments>http://blogls.top/2023/05/29/2023-ICLR-Single-shot-General-Hyper-parameter-Optimization-for-Federated-Learning/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>2022|Enable Deep Learning on Mobile Devices: Methods, Systems, and Applications|韩松|CCF-B</title>
      <link>http://blogls.top/2023/05/28/2022-Enable-Deep-Learning-on-Mobile-Devices-Methods-Systems-and-Applications-%E9%9F%A9%E6%9D%BE-CCF-B/</link>
      <guid>http://blogls.top/2023/05/28/2022-Enable-Deep-Learning-on-Mobile-Devices-Methods-Systems-and-Applications-%E9%9F%A9%E6%9D%BE-CCF-B/</guid>
      <pubDate>Sun, 28 May 2023 14:33:33 GMT</pubDate>
      
      <description>&lt;blockquote&gt;
&lt;p&gt;链接：&lt;a class=&quot;link&quot; href=&quot;https://arxiv.org/pdf/2204.11786.pdf&quot;&gt;https://arxiv.org/pdf/2204.11786.pdf &lt;i class=&quot;fa-regular fa-arrow-up-right-from-square fa-sm&quot;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&quot;1-总结&quot;&gt;&lt;a href=&quot;#1-总结&quot; class=&quot;headerlink&quot; title=&quot;1.总结&quot;&gt;&lt;/a&gt;1.总结&lt;/h1&gt;&lt;p&gt;本文介绍了一种用于在移动设备上实现深度学习的方法、系统和应用。文章从介绍流行的模型压缩方法开始，包括剪枝、分解、量化以及紧凑模型设计。为了减少这些手动解决方案的大量设计成本，讨论了每个人的AutoML框架，如&lt;strong&gt;神经架构搜索（NAS）&lt;/strong&gt;和&lt;strong&gt;自动剪枝和量化&lt;/strong&gt;。然后涵盖了高效的设备内训练，以便在移动设备上基于本地数据实现用户定制。除了通用加速技术，还展示了通过利用它们的空间稀疏性和时间/令牌冗余来加速点云、视频和自然语言处理的几种任务特定加速。最后，为了支持所有这些算法进展，从软件和硬件角度介绍了高效深度学习系统设计。&lt;/p&gt;
&lt;p&gt;&lt;img lazyload=&quot;&quot; src=&quot;/images/loading.svg&quot; data-src=&quot;https://raw.githubusercontent.com/ShuaiLv-JNU/blogImage/main/img/202305282317848.png&quot;&gt;&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<blockquote><p>链接：<a class="link" href="https://arxiv.org/pdf/2204.11786.pdf">https://arxiv.org/pdf/2204.11786.pdf <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p></blockquote><h1 id="1-总结"><a href="#1-总结" class="headerlink" title="1.总结"></a>1.总结</h1><p>本文介绍了一种用于在移动设备上实现深度学习的方法、系统和应用。文章从介绍流行的模型压缩方法开始，包括剪枝、分解、量化以及紧凑模型设计。为了减少这些手动解决方案的大量设计成本，讨论了每个人的AutoML框架，如<strong>神经架构搜索（NAS）</strong>和<strong>自动剪枝和量化</strong>。然后涵盖了高效的设备内训练，以便在移动设备上基于本地数据实现用户定制。除了通用加速技术，还展示了通过利用它们的空间稀疏性和时间/令牌冗余来加速点云、视频和自然语言处理的几种任务特定加速。最后，为了支持所有这些算法进展，从软件和硬件角度介绍了高效深度学习系统设计。</p><p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/ShuaiLv-JNU/blogImage/main/img/202305282317848.png"></p><span id="more"></span><h1 id="2-优势"><a href="#2-优势" class="headerlink" title="2.优势"></a>2.优势</h1><p>与以前的解决方案相比，本文旨在涵盖更广泛的高效深度学习方法和应用：从手动到自动，从新原语/操作设计到设计空间探索，从训练到推理，从算法到硬件，从通用目的到应用特定优化。</p><h1 id="3-细节"><a href="#3-细节" class="headerlink" title="3.细节"></a>3.细节</h1><h2 id="3-1剪枝"><a href="#3-1剪枝" class="headerlink" title="3.1剪枝"></a>3.1剪枝</h2><p>DNN通常是过度参数化的，修剪可以去除神经网络中的冗余元素，以减少模型大小和计算成本。</p><p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/ShuaiLv-JNU/blogImage/main/img/202305282324146.png"></p><p><strong>Step1：选择修剪粒度</strong></p><ul><li><p>颗粒度修剪：</p><ul><li><p>去除权重张量中的个别元素（细粒度）</p></li><li><p>基于模式的修剪（细粒度）</p></li><li><p>通道修剪（粗粒度）</p></li></ul></li><li><p>硬件加速</p></li></ul><p><strong>Step2：重要性标准</strong></p><p>确定哪些权重要被修剪对于修剪后的模型性能也是至关重要的。在模型训练后，有几种重要性标准的启发式方法来估计每个权重的重要性。</p><p><strong>Step3：训练方法</strong></p><p>在大的压缩比下，直接删除深度神经网络中的权重将大大降低准确性。因此，需要进行一些训练/微调来恢复性能损失。微调可以在修剪后进行，以恢复性能下降。</p><h2 id="3-2低秩因子化"><a href="#3-2低秩因子化" class="headerlink" title="3.2低秩因子化"></a>3.2低秩因子化</h2><p>使用矩阵/张量分解来降低深度神经网络中卷积或全连接层的复杂性，使用低秩过滤器来加速卷积的想法在信号处理领域已被长期研究，比如SVD。</p><h2 id="3-3量化"><a href="#3-3量化" class="headerlink" title="3.3量化"></a>3.3量化</h2><p>通过减少表示深层网络所需的每个权重的比特来压缩网络。在硬件支持下，量化后的网络可以有更快的推理速度。</p><p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/ShuaiLv-JNU/blogImage/main/img/202305282333445.png"></p><ul><li><strong>四舍五入方案</strong>：为了将全精度权重(32位浮点值)量化为低精度，四舍五入被用来将浮点值映射到一个量化桶中。<ul><li>k-means：落入同一类的共享权重</li><li>线性/统一量化：范围截断后直接将浮点值四舍五入为最接近的量化值。</li></ul></li><li><strong>位精度</strong>：使用不同的位来权衡模型大小，较低的位精度模型小，但精度下降也大。全精度权重和激活都使用FP32。半精度使用FP16。INT8常用于GPU加速。</li><li><strong>量化方案</strong>：①对于更高精度的量化( 如INT8)，可以进行<strong>训练后量化</strong>，在全精度模型训练后对权重和激活进行量化，激活的量化范围是通过计算训练集上的分布来确定的。应用训练后的INT8量化通常会导致精度的微小损失或没有损失。最近的工作也研究了INT4模型的训练后量化问题。②<strong>量化感知训练</strong>可以通过在训练期间模拟推理时间量化来减少量化精度的损失，训练期间的前向传递与测试时间一致，这有助于设备上的部署。</li></ul><h2 id="3-4-知识蒸馏"><a href="#3-4-知识蒸馏" class="headerlink" title="3.4 知识蒸馏"></a>3.4 知识蒸馏</h2><p>KD将大模型（教师）中学习的“暗知识”转移到小模型（学生）中。</p><h2 id="3-5紧凑模型设计"><a href="#3-5紧凑模型设计" class="headerlink" title="3.5紧凑模型设计"></a>3.5紧凑模型设计</h2><ul><li>Mobile net</li><li>shuffle net：引入了两个新的操作，顺时针分组卷积和channel shuffle。</li><li>squeeze net</li></ul><h2 id="3-6NAS"><a href="#3-6NAS" class="headerlink" title="3.6NAS"></a>3.6NAS</h2><p>——</p><h2 id="3-7自动模型压缩"><a href="#3-7自动模型压缩" class="headerlink" title="3.7自动模型压缩"></a>3.7自动模型压缩</h2><p>模型压缩方法可以提高部署模型的效率。然而，模型压缩的性能主要受超参数的影响。例如，深度网络中的不同层有不同的能力和敏感度( 例如，CNN中的第一层通常对修剪非常敏感 )。因此我们应该<strong>对网络的不同层应用不同的修剪比例</strong>，以达到最佳性能。设计空间如此之大，以至于人类的启发式方法通常是次优的，而且人工模型压缩也很耗时。为此，提出了自动模型压缩，以找到好的压缩策略。</p><ul><li><p><strong>自动剪枝</strong>：传统的模型修剪技术依赖于手工制作的特征，需要领域专家探索庞大的设计空间在模型大小、速度和精度之间进行权衡，这通常是次优的，而且很费时间。AMC利用强化学习来有效地对设计空间进行采样，并为给定的网络找到最佳的剪枝策略。奖励被计算为准确性和FLOP的函数；MetaPruning首先训练了一个PruningNet，一种<strong>元网络</strong>，它能够为给定的目标网络的任何修剪结构生成权重参数，然后用它来搜索不同约束条件下的最佳修剪策略。该元网络可用于直接测量压缩精度，而无需进行微调。</p></li><li><p><strong>自动量化</strong>：混合精度量化也需要大量的努力来决定每一层的最佳位宽，以实现最佳的精度-性能权衡。硬件感知自动量化(HAQ)利用强化学习来自动确定量化策略；一种用于混合精度量化的二阶量化方法Hessian AWare Quantization ( HAWQ )允许根据各层的Hessian谱，自动选择各层的相对量化精度，当应用于大型语言模型时，还显示出卓越的性能。</p></li></ul><h2 id="3-8联合压缩与NAS"><a href="#3-8联合压缩与NAS" class="headerlink" title="3.8联合压缩与NAS"></a>3.8联合压缩与NAS</h2><ul><li>顺序优化：即分别应用这两种技术。</li><li>联合优化（端到端）</li></ul><p><img lazyload="" src="/images/loading.svg" data-src="https://raw.githubusercontent.com/ShuaiLv-JNU/blogImage/main/img/202305282353765.png"></p><h2 id="3-9高效的设备上学习"><a href="#3-9高效的设备上学习" class="headerlink" title="3.9高效的设备上学习"></a>3.9高效的设备上学习</h2><ul><li>梯度检查点</li><li>激活修剪</li><li>低比特训练</li><li>梯度压缩</li></ul><h2 id="3-10高效的迁移学习"><a href="#3-10高效的迁移学习" class="headerlink" title="3.10高效的迁移学习"></a>3.10高效的迁移学习</h2><p>——</p><h2 id="3-11联邦学习"><a href="#3-11联邦学习" class="headerlink" title="3.11联邦学习"></a>3.11联邦学习</h2><p>联合学习允许多个客户联合训练一个模型，而不需要明确分享他们的数据。随着个人数据的隐私问题越来越受到关注，这也导致了在不破坏隐私的情况下进行训练的需求越来越大。虽然在部署中拥有许多边缘设备是很常见的，但联合学习提供了一种利用所有设备的方法，并解决了安全问题，因为本地数据从未离开过客户端。与配备高端网络基础设施的集群不同，边缘设备通常与功能较弱的网络(Wi-Fi)相连在<strong>这种情况下，带宽很低，延迟很高</strong>，传统方法的扩展性很差。为了消除瓶颈，联合平均、梯度压缩和量化大大减少了传输的比特，以降低带宽要求，延迟更新处理了延迟的问题。</p>]]></content:encoded>
      
      
      
      <category domain="http://blogls.top/tags/PaperReading/">PaperReading</category>
      
      
      <comments>http://blogls.top/2023/05/28/2022-Enable-Deep-Learning-on-Mobile-Devices-Methods-Systems-and-Applications-%E9%9F%A9%E6%9D%BE-CCF-B/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
